{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If2PTdzkfzo3"
   },
   "source": [
    "# Connectome Pipeline\n",
    "\n",
    "Hi and welcome to the Connectome Pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLI7xV4Lfzo5"
   },
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "In the first step, you will preprocess the CONN Matlab files to a analysis ready dataset.\n",
    "\n",
    "Here is an overview on the parameters for the preprocessing pipeline. Parameters marked with a (*) are optional.\n",
    "\n",
    "\n",
    "+    *matlab_dir*: path to matlab files\n",
    "+    *excel_path*: path to excel list\n",
    "+    *save_file*: If false return as pd dataframe\n",
    "+    *preprocessing_type*: conn for connectivity matrix, \"aggregation\" for aggregated conn matrix, \"graph\" for graph matrices\n",
    "+    *write_dir**: path where to write the dataset to if save_file = True\n",
    "+    *network**: Yeo7 or Yeo17 network (only applicable if preprocessing_type = aggregation)\n",
    "+    *statistic**: Summary statistic to be applied (only applicable if preprocessing_type = aggregation)\n",
    "+    *upper**: boolean whether only upper diagonal elements of connecivity matrices should be used\n",
    "+    *split_size**: the size of the train dataset (default .8)\n",
    "+    *seed**: pass an int for reproducibility purposes (default 42)\n",
    "+    *file_format**: Pass \"h5\" for further modelling in python or \"csv\" for R (default \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFRC1BcHfzo5"
   },
   "outputs": [],
   "source": [
    "from src.preprocessing.preprocessing_matlab_files import transform_mat_write_to_hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54xpo4usfzo6"
   },
   "outputs": [],
   "source": [
    "matlab_dir = \"C:/Users/likai/Desktop/My Life/Master/3. Semester/Innolabs/Connectome Git/data/Matlab/\" # Enter the directory for the matlab files\n",
    "excel_path = \"C:/Users/likai/Desktop/My Life/Master/3. Semester/Innolabs/Connectome Git/data/DELCODE_dataset_910.xlsx\" # Enter the directory for the corresponding excel sheet\n",
    "write_dir = \"C:/Users/likai/Desktop/My Life/Master/3. Semester/Innolabs/Connectome Git/data/\" # ...\n",
    "save_file = False # rename to export file\n",
    "preprocessing_type = 'conn' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQMLPvI_fzo6",
    "outputId": "87dc04d7-8432-4202-9bb9-a6f3e01cf848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files\n",
      "Starting Preprocessing\n",
      "Creating Final Dataset\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df = transform_mat_write_to_hdf(matlab_dir = matlab_dir, excel_path = excel_path, write_dir = write_dir,\n",
    "                           save_file = save_file, preprocessing_type = 'conn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgNDTjc3fzo7"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GesXXX0sfzo7"
   },
   "source": [
    "## 2. Modelling\n",
    "\n",
    "In the second step, you can decide between running the new input files on a pretrained model or train a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIU_ujK1fzo7"
   },
   "source": [
    "### 2.1  Data preparation\n",
    "Preparation of the data for modelling. Creates the target variable, drops unnecessary columns, performs a train/test split (if wanted). \\\\\n",
    "The user has to specify:\n",
    "- *classification*: is it a classification task (True) or a regression task (False)\n",
    "- *columns_drop*: which variables shoulnd't be used for modelling\n",
    "- *target*: what is the name of the target variable\n",
    "- *y_0, y_1* (only relevant for classification task): which values of the target variable are 0, which are 1\n",
    "- *train_size*: size of the training data\n",
    "- *seed*: a seed to ensure reproducibility of train/test split\n",
    "- split: should a train/test split be performed or not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8RM0TUufzo7"
   },
   "outputs": [],
   "source": [
    "from src.preprocessing import data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTSdzorufzo7"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train, test])\n",
    "classification = True\n",
    "columns_drop = [\"ConnID\", \"Repseudonym\", \"siteid\", \"visdat\", \"MEM_score\", \"Apoe\", \"IDs\"]\n",
    "target = \"prmdiag\"\n",
    "y_0 = [0]\n",
    "y_1 = [2, 3]\n",
    "train_size = 0.8\n",
    "seed = 123\n",
    "split = True"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# preparation of data\n",
    "ytrain, Xtrain, ytest, Xtest = prepare_data(data = data, classification = classification,\n",
    "                         columns_drop = columns_drop, target = target, y_0 = y_0, y_1 = y_1,\n",
    "                         train_size = train_size, seed = seed, split = split)\n",
    "\n",
    "\n",
    "pd.concat([ytest, Xtest], axis = 1) # test data"
   ],
   "metadata": {
    "id": "fIi5_9ATgTS4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX99AfITfzo8"
   },
   "source": [
    "### 2.2 Run Model or get pretrained model\n",
    "\n",
    "Selection which model should be used and whether a pretrained model or newly trained model is desired.\n",
    "\n",
    "ToDo: Various trained models are available on the github page under xxx/xxx...\n",
    "\n",
    "The user has to specify:\n",
    "- X_train: training data coming from the previous step\n",
    "- y_train: values of target variable for the training data coming from the previous step\n",
    "- model: which model should be used (options are: \"elnet\" for elastic net, \"gboost\" for gradient boosting, \"rf\" for random forest and \"cnn\" for convolutional neural network)\n",
    "- pretrained: is a pretrained model wanted or should the training data be used to fit a new one. (True = pretrained, False = new fit)\n",
    "- model_path: the full path to the desired pretrained model if one should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AaJOVUgNfzo8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.framework'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-220a9b8478c6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msrc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodel_framework\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'src.framework'"
     ]
    }
   ],
   "source": [
    "from src.framework import model_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lsEUA9ffzo8"
   },
   "outputs": [],
   "source": [
    "model = model_framework(X_train = Xtrain,\n",
    "                        y_train = ytrain,\n",
    "                        model = \"cnn\",\n",
    "                        pretrained = True,\n",
    "                        model_path = \"/content/drive/MyDrive/Colab Notebooks/Innolab/ccnn_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnxI8ZWEfzo8"
   },
   "source": [
    "## 3. Model Evaluation\n",
    "\n",
    "In this step you can now evaluate the Model on a set of prespecified metrics.\n",
    "\n",
    "+ For Classification: Accuracy, Precision, Recall, F1 and AUC\n",
    "+ For Regression: MSE, MAE and R2\n",
    "\n",
    "Checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m20cNjWqfzo8"
   },
   "outputs": [],
   "source": [
    "from src.models.evaluation import model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wip6Acnsfzo8"
   },
   "outputs": [],
   "source": [
    "model = model\n",
    "X_test = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tymSZ5sefzo8"
   },
   "outputs": [],
   "source": [
    "model_evaluation(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY8r5oMVfzo8"
   },
   "source": [
    "## 4. Feature Visualization and Interpretation\n",
    "\n",
    "In the final step you can choose between several feature visualization and interpretation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii5PDl5efzo8"
   },
   "outputs": [],
   "source": [
    "from src.visualization.viz_utils import ordered_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5FzFtovfzo8"
   },
   "outputs": [],
   "source": [
    "model , X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "Connectome Pipeline.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}