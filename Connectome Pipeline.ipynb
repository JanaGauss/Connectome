{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If2PTdzkfzo3"
   },
   "source": [
    "# Connectome Pipeline\n",
    "\n",
    "Hi and welcome to the Connectome Pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLI7xV4Lfzo5"
   },
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "In the first step, you will preprocess the CONN Matlab files to an analysis ready dataset.\n",
    "\n",
    "Here is an overview on the parameters for the preprocessing pipeline. Parameters marked with a (*) are optional.\n",
    "\n",
    "\n",
    "+    *matlab_dir*: path to matlab files\n",
    "+    *excel_path*: path to excel list\n",
    "+    *preprocessing_type*: conn for connectivity matrix or \"aggregation\" for aggregated conn matrix\n",
    "+    *export_file**: If false return as pd dataframe\n",
    "+    *write_dir**: path where to write the dataset to if save_file = True\n",
    "+    *network**: Yeo7 or Yeo17 network (only applicable if preprocessing_type = aggregation)\n",
    "+    *statistic**: Summary statistic to be applied (only applicable if preprocessing_type = aggregation)\n",
    "+    *upper**: boolean whether only upper diagonal elements of connecivity matrices should be used\n",
    "+    *file_format**: Pass \"h5\" for further modelling in python or \"csv\" for R (default \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2840,
     "status": "ok",
     "timestamp": 1645194398205,
     "user": {
      "displayName": "Jonas Klingele",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01851783090542566825"
     },
     "user_tz": -60
    },
    "id": "TVio-2b3OjCQ",
    "outputId": "848bd468-3749-47f3-e89b-6eb03c491021"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1645194596416,
     "user": {
      "displayName": "Jonas Klingele",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01851783090542566825"
     },
     "user_tz": -60
    },
    "id": "JFRC1BcHfzo5"
   },
   "outputs": [],
   "source": [
    "from connectome.preprocessing.preprocessing_matlab_files import preprocess_mat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1645194992214,
     "user": {
      "displayName": "Jonas Klingele",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01851783090542566825"
     },
     "user_tz": -60
    },
    "id": "54xpo4usfzo6"
   },
   "outputs": [],
   "source": [
    "matlab_dir = r\"C:\\Users\\Kai\\Desktop\\My Life\\Master\\3. Semester\\Innolabs\\Connectome\\data\\10\\10\\conn_data\" # Enter the directory for the matlab files\n",
    "excel_path = r\"C:\\Users\\Kai\\Desktop\\My Life\\Master\\3. Semester\\Innolabs\\Connectome\\data\\10\\10\\example_data_10.xlsx\" # Enter the directory for the corresponding excel sheet\n",
    "preprocessing_type = 'conn'\n",
    "write_dir = \"\" # ...\n",
    "export_file = False # rename to export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fQMLPvI_fzo6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files\n",
      "Starting Preprocessing\n",
      "Creating Final Dataset\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_mat_files(matlab_dir = matlab_dir, excel_path = excel_path, preprocessing_type = preprocessing_type,\n",
    "                          write_dir = write_dir, export_file = export_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dgNDTjc3fzo7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>edyears</th>\n",
       "      <th>Apoe</th>\n",
       "      <th>target</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>ConnID</th>\n",
       "      <th>IDs</th>\n",
       "      <th>1_2</th>\n",
       "      <th>...</th>\n",
       "      <th>6_7</th>\n",
       "      <th>6_8</th>\n",
       "      <th>6_9</th>\n",
       "      <th>6_10</th>\n",
       "      <th>7_8</th>\n",
       "      <th>7_9</th>\n",
       "      <th>7_10</th>\n",
       "      <th>8_9</th>\n",
       "      <th>8_10</th>\n",
       "      <th>9_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.942277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064793</td>\n",
       "      <td>0.975841</td>\n",
       "      <td>0.234597</td>\n",
       "      <td>-3.256017</td>\n",
       "      <td>2.714773</td>\n",
       "      <td>-2.952573</td>\n",
       "      <td>-3.225470</td>\n",
       "      <td>-0.834634</td>\n",
       "      <td>-2.281607</td>\n",
       "      <td>0.490368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.337648</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.595689</td>\n",
       "      <td>-0.474086</td>\n",
       "      <td>-3.539505</td>\n",
       "      <td>-1.806304</td>\n",
       "      <td>-0.495115</td>\n",
       "      <td>1.660703</td>\n",
       "      <td>-1.528401</td>\n",
       "      <td>4.027515</td>\n",
       "      <td>2.467213</td>\n",
       "      <td>0.971484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.076518</td>\n",
       "      <td>...</td>\n",
       "      <td>2.386448</td>\n",
       "      <td>2.177649</td>\n",
       "      <td>-2.782558</td>\n",
       "      <td>1.516519</td>\n",
       "      <td>0.511374</td>\n",
       "      <td>0.640020</td>\n",
       "      <td>-1.247038</td>\n",
       "      <td>-1.335651</td>\n",
       "      <td>0.252126</td>\n",
       "      <td>1.324432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.867223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656894</td>\n",
       "      <td>-1.630556</td>\n",
       "      <td>-1.468686</td>\n",
       "      <td>-3.093310</td>\n",
       "      <td>-3.076284</td>\n",
       "      <td>-1.983045</td>\n",
       "      <td>-0.653831</td>\n",
       "      <td>-2.407441</td>\n",
       "      <td>1.524945</td>\n",
       "      <td>0.437020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.120163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523197</td>\n",
       "      <td>-2.129155</td>\n",
       "      <td>-0.779487</td>\n",
       "      <td>-0.570189</td>\n",
       "      <td>1.317503</td>\n",
       "      <td>-1.529356</td>\n",
       "      <td>0.374784</td>\n",
       "      <td>-0.939822</td>\n",
       "      <td>2.208215</td>\n",
       "      <td>-1.170817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   age  sex  edyears  Apoe  target  subject_id  ConnID  IDs  \\\n",
       "0         1.0  72.0  1.0     18.0   1.0     1.0         1.0     1.0  1.0   \n",
       "1         2.0  80.0  0.0     18.0   1.0     1.0         2.0     2.0  2.0   \n",
       "2         3.0  87.0  0.0     19.0   0.0     0.0         3.0     3.0  3.0   \n",
       "3         5.0  81.0  1.0     10.0   0.0     0.0         5.0     5.0  5.0   \n",
       "4         8.0  84.0  1.0     11.0   1.0     0.0         8.0     8.0  8.0   \n",
       "\n",
       "        1_2  ...       6_7       6_8       6_9      6_10       7_8       7_9  \\\n",
       "0 -2.942277  ... -0.064793  0.975841  0.234597 -3.256017  2.714773 -2.952573   \n",
       "1  3.337648  ... -1.595689 -0.474086 -3.539505 -1.806304 -0.495115  1.660703   \n",
       "2  3.076518  ...  2.386448  2.177649 -2.782558  1.516519  0.511374  0.640020   \n",
       "3 -0.867223  ... -0.656894 -1.630556 -1.468686 -3.093310 -3.076284 -1.983045   \n",
       "4  0.120163  ... -0.523197 -2.129155 -0.779487 -0.570189  1.317503 -1.529356   \n",
       "\n",
       "       7_10       8_9      8_10      9_10  \n",
       "0 -3.225470 -0.834634 -2.281607  0.490368  \n",
       "1 -1.528401  4.027515  2.467213  0.971484  \n",
       "2 -1.247038 -1.335651  0.252126  1.324432  \n",
       "3 -0.653831 -2.407441  1.524945  0.437020  \n",
       "4  0.374784 -0.939822  2.208215 -1.170817  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GesXXX0sfzo7"
   },
   "source": [
    "## 2. Modelling\n",
    "\n",
    "In the second step, you can decide between running the new input files on a pretrained model or train a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIU_ujK1fzo7"
   },
   "source": [
    "### 2.1  Data preparation\n",
    "Preparation of the data for modelling. Creates the target variable, drops unnecessary columns, performs a train/test split (if wanted). \\\\\n",
    "The user has to specify:\n",
    "- *classification*: is it a classification task (True) or a regression task (False)\n",
    "- *columns_drop*: which variables shoulnd't be used for modelling\n",
    "- *target*: what is the name of the target variable\n",
    "- *y_0, y_1* (only relevant for classification task): which values of the target variable are 0, which are 1\n",
    "- *train_size*: size of the training data\n",
    "- *seed*: a seed to ensure reproducibility of train/test split\n",
    "- split: should a train/test split be performed or not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "F8RM0TUufzo7"
   },
   "outputs": [],
   "source": [
    "from connectome.preprocessing.data_preparation import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZTSdzorufzo7"
   },
   "outputs": [],
   "source": [
    "classification = True\n",
    "columns_drop = [\"ConnID\", \"Apoe\", \"subject_id\"]\n",
    "target = \"target\"\n",
    "y_0 = [0]\n",
    "y_1 = [1]\n",
    "train_size = 0.8\n",
    "seed = 1855\n",
    "split = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fIi5_9ATgTS4"
   },
   "outputs": [],
   "source": [
    "# preparation of data\n",
    "X_train, y_train, X_test, y_test = prepare_data(data = df, classification = classification,\n",
    "                                                columns_drop = columns_drop, target = target, y_0 = y_0, y_1 = y_1,\n",
    "                                                train_size = train_size, seed = seed, split = split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX99AfITfzo8"
   },
   "source": [
    "### 2.2 Run Model or get pretrained model\n",
    "\n",
    "Selection which model should be used and whether a pretrained model or newly trained model is desired.\n",
    "\n",
    "You can find a selection fo pretrained models under the models folder.\n",
    "\n",
    "The user has to specify:\n",
    "- X_train: training data coming from the previous step\n",
    "- y_train: values of target variable for the training data coming from the previous step\n",
    "- model: which model should be used (options are: \"elnet\" for elastic net, \"gboost\" for gradient boosting, \"rf\" for random forest and \"cnn\" for convolutional neural network)\n",
    "- pretrained: is a pretrained model wanted or should the training data be used to fit a new one. (True = pretrained, False = new fit)\n",
    "- model_path: the full path to the desired pretrained model if one should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AaJOVUgNfzo8",
    "outputId": "eed84514-09c7-4c74-e8cf-4359da2b57a4"
   },
   "outputs": [],
   "source": [
    "from connectome.models.framework import model_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning flat array to matrix\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 155 into shape (31,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-18d4ea32d767>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                        patience = 1)\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\My Life\\Master\\3. Semester\\Innolabs\\Connectome\\connectome\\models\\framework.py\u001b[0m in \u001b[0;36mmodel_framework\u001b[1;34m(X_train, y_train, model, pretrained, model_path, save, t_direct, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0mrmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_brainnet_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;31m# saving model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\My Life\\Master\\3. Semester\\Innolabs\\Connectome\\connectome\\models\\brainnet_cnn.py\u001b[0m in \u001b[0;36mmodel_brainnet_cnn\u001b[1;34m(X, y, aggregation, reorder, augmentation, scale, augm_fact, batch_size, epochs, patience, validation_size, E2E_filter, E2N_filter, N2G_tiler, dense_filter, dropout_rate, kernel_regularizer, kernel_initializer, optimizer, activation, loss)\u001b[0m\n\u001b[0;32m     91\u001b[0m     X_train, X_train_struc, y_train = preprocess_for_cnn(X, y, aggregation=aggregation, reorder=reorder,\n\u001b[0;32m     92\u001b[0m                                                          \u001b[0maugmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                                                          scale=scale, augmentation_factor=augm_fact)\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;31m# create validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\My Life\\Master\\3. Semester\\Innolabs\\Connectome\\connectome\\models\\brainnet_cnn.py\u001b[0m in \u001b[0;36mpreprocess_for_cnn\u001b[1;34m(X, y, aggregation, reorder, augmentation, scale, augmentation_factor)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0mX_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_struc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mX_struc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_struc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mX_struc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_struc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 155 into shape (31,3)"
     ]
    }
   ],
   "source": [
    "model = model_framework(X_train = X_train,\n",
    "                        y_train = y_train,\n",
    "                        model = \"cnn\",\n",
    "                        pretrained = False,\n",
    "                        model_path = None,\n",
    "                        epochs =1,\n",
    "                       patience = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "aggregation = False\n",
    "augmentation = False\n",
    "reorder = False\n",
    "\n",
    "X_img_cols = []\n",
    "X_struc_cols = []\n",
    "for x in X.columns:\n",
    "    if len(x.split(\"_\")) > 1 and x.split(\"_\")[0].isdigit() and x.split(\"_\")[1].isdigit():\n",
    "        X_img_cols.append(x)\n",
    "    else:\n",
    "        X_struc_cols.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if augmentation:\n",
    "    print(\"Starting Data Augmentation\")\n",
    "    X_img_aug, X_struc_aug, y_aug = augmented_data(X, y, X_img_cols, X_struc_cols, sd=scale,\n",
    "                                                   augm_fact=augmentation_factor)\n",
    "    # merging augmented data with input data\n",
    "    X_img = pd.concat([X[X_img_cols], X_img_aug])\n",
    "    X_struc = pd.concat([X[X_struc_cols], X_struc_aug])\n",
    "    y = np.concatenate([np.array(y), y_aug], axis=0)\n",
    "else:\n",
    "    X_img = X[X_img_cols]\n",
    "    X_struc = X[X_struc_cols]\n",
    "    y = np.array(y)\n",
    "\n",
    "if aggregation:\n",
    "    n_c = 8\n",
    "    n_train = len(X_img)\n",
    "    X_train_2d = np.zeros(n_train * n_c * n_c).reshape(n_train, n_c, n_c)\n",
    "\n",
    "    # turn array to matrix\n",
    "    for i in range(n_train):\n",
    "        X_train_2d[i] = flat_to_mat_aggregation(X_img.iloc[i, :])\n",
    "\n",
    "    stacked = np.stack(X_train_2d, axis=0)\n",
    "\n",
    "else:\n",
    "    n_c = dtl.flat_to_mat(X_img.iloc[0, :]).shape[0]\n",
    "    n_train = len(X_img)\n",
    "    X_train_2d = np.zeros(n_train * n_c * n_c).reshape(n_train, n_c, n_c)\n",
    "\n",
    "    # turn array to matrix\n",
    "    for i in range(n_train):\n",
    "        X_train_2d[i] = dtl.flat_to_mat(X_img.iloc[i, :])\n",
    "\n",
    "    if reorder:\n",
    "        stacked = np.stack(reorder_matrices_regions(X_train_2d, network='yeo7'), axis=0)\n",
    "    else:\n",
    "        stacked = np.stack(X_train_2d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-f42c6bb02df8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_struc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mX_struc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_struc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_struc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_struc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_struc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "X_img = stacked.reshape(stacked.shape[0], stacked.shape[1], stacked.shape[2], 1)\n",
    "if X_struc.shape[1] != 0:\n",
    "    X_struc = X_struc.to_numpy().reshape(stacked.shape[0], X_struc.shape[1])\n",
    "else:\n",
    "    X_struc = X_struc.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26961509,  0.98648887,  0.90748521, -1.07646857, -1.26961509],\n",
       "       [-0.10345012,  1.23715407,  0.90748521,  0.94598753, -0.10345012],\n",
       "       [-1.05095916,  1.23715407,  0.90748521, -1.41354459, -1.05095916],\n",
       "       [-0.6865326 ,  1.36248667,  0.90748521, -0.40231654, -0.6865326 ],\n",
       "       [-0.97807385, -1.39483057,  0.90748521,  0.60891151, -0.97807385],\n",
       "       [ 0.91694423, -0.26683715,  0.90748521,  0.94598753,  0.91694423],\n",
       "       [-1.48827102,  0.61049106,  0.90748521, -1.41354459, -1.48827102],\n",
       "       [ 0.0423205 ,  0.23449326,  0.90748521, -1.07646857,  0.0423205 ],\n",
       "       [ 1.06271485,  0.23449326, -1.10194633, -1.07646857,  1.06271485],\n",
       "       [ 1.3542561 ,  0.35982586, -1.10194633,  0.60891151,  1.3542561 ],\n",
       "       [-1.63404164,  1.36248667, -1.10194633,  1.62013957, -1.63404164],\n",
       "       [-0.17633543,  1.11182147, -1.10194633, -0.73939255, -0.17633543],\n",
       "       [ 1.28137079, -0.39216975,  0.90748521, -1.07646857,  1.28137079],\n",
       "       [-0.61364729,  0.73582366,  0.90748521, -0.06524052, -0.61364729],\n",
       "       [ 0.55251768, -0.39216975,  0.90748521, -0.06524052,  0.55251768],\n",
       "       [ 0.84405892,  1.36248667, -1.10194633, -1.41354459,  0.84405892],\n",
       "       [ 0.98982954, -0.39216975, -1.10194633,  0.60891151,  0.98982954],\n",
       "       [ 1.71868265, -1.89616098, -1.10194633,  0.60891151,  1.71868265],\n",
       "       [ 1.57291203,  0.61049106, -1.10194633,  0.94598753,  1.57291203],\n",
       "       [-0.24922074, -0.64283496, -1.10194633, -1.07646857, -0.24922074],\n",
       "       [-0.32210605, -0.76816756, -1.10194633, -0.40231654, -0.32210605],\n",
       "       [-0.75941792,  1.23715407, -1.10194633,  0.2718355 , -0.75941792],\n",
       "       [-0.83230323, -0.64283496,  0.90748521, -1.7506206 , -0.83230323],\n",
       "       [-0.54076198, -1.89616098,  0.90748521,  0.94598753, -0.54076198],\n",
       "       [ 0.62540299, -0.39216975,  0.90748521, -1.07646857,  0.62540299],\n",
       "       [ 1.42714141,  0.73582366,  0.90748521,  0.60891151,  1.42714141],\n",
       "       [-0.90518854, -1.89616098, -1.10194633,  0.94598753, -0.90518854],\n",
       "       [ 0.11520581, -0.51750236, -1.10194633,  0.94598753,  0.11520581],\n",
       "       [ 0.6982883 , -1.01883277, -1.10194633,  1.28306355,  0.6982883 ],\n",
       "       [-1.77981227, -0.51750236,  0.90748521,  1.28306355, -1.77981227],\n",
       "       [ 0.18809112, -0.39216975,  0.90748521,  0.94598753,  0.18809112]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import connectome.preprocessing.data_loader as dtl\n",
    "from connectome.preprocessing.reorder_matrices_regions import reorder_matrices_regions\n",
    "from connectome.preprocessing.data_loader import flat_to_mat_aggregation\n",
    "from connectome.models.E2E_conv import E2E_conv\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnxI8ZWEfzo8"
   },
   "source": [
    "## 3. Model Evaluation\n",
    "\n",
    "In this step you can now evaluate the Model on a set of prespecified metrics.\n",
    "\n",
    "+ For Classification: Accuracy, Precision, Recall, F1 and AUC\n",
    "+ For Regression: MSE, MAE and R2\n",
    "\n",
    "Checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m20cNjWqfzo8"
   },
   "outputs": [],
   "source": [
    "from connectome.models.evaluation import model_evaluation\n",
    "from connectome.models.brainnet_cnn import preprocess_test_data_for_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a cnn Model was trained uncomment the next line to transform the test_dataset to the right input format for the CNN with the same settings\n",
    "# X_test, y_test = preprocess_test_data_for_cnn(X_test, y_test, aggregation=False, reorder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tymSZ5sefzo8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_evaluation(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY8r5oMVfzo8"
   },
   "source": [
    "## 4. Feature Visualization and Interpretation\n",
    "\n",
    "In the final step you can choose between several feature visualization and interpretation techniques.\n",
    "\n",
    "The user has to specify:\n",
    "+        model: the model from  step 2\n",
    "+        X: X_test dataframe\n",
    "+        y: Target test dataframe\n",
    "+        viz_method: Choice  of \"GFI\" , \"GFI_only\", \"FI\" , \"FI_only\", \"elastic_net\", \"shapley\" and \"feature_attribution\"\n",
    "\n",
    "Visualization methods:\n",
    "+ GFI: Grouped Permutation Feature Importance (based on yeo7 network)\n",
    "+ GFI_only: Group only Permutation Feature Importance (based on yeo7 network)\n",
    "+ FI: Permutation Feature Importance\n",
    "+ FI_only: Version of Group only Permutation Feature Importance but for every feature, not groups\n",
    "+ elastic_net: Visualization of the elastic net coefficients\n",
    "+ shapley: Summary plot for shapley values\n",
    "+ feature_attribution: Neural Network Visulization with Saliency Maps\n",
    "\n",
    "For more details and customization of plots see our documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii5PDl5efzo8"
   },
   "outputs": [],
   "source": [
    "from connectome.visualization.viz_framework import visualization_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5FzFtovfzo8"
   },
   "outputs": [],
   "source": [
    "viz = visualization_framework(model=model,X=X_test,\n",
    "                              y=y_test, viz_method=\"feature_attribution\", method='saliency', average=True, ordered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Connectome Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
