{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If2PTdzkfzo3"
   },
   "source": [
    "# Connectome Pipeline\n",
    "\n",
    "Hi and welcome to the Connectome Pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLI7xV4Lfzo5"
   },
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "In the first step, you will preprocess the CONN Matlab files to an analysis ready dataset.\n",
    "\n",
    "Here is an overview on the parameters for the preprocessing pipeline. Parameters marked with a (*) are optional.\n",
    "\n",
    "\n",
    "+    *matlab_dir*: path to matlab files\n",
    "+    *excel_path*: path to excel list\n",
    "+    *preprocessing_type*: conn for connectivity matrix or \"aggregation\" for aggregated conn matrix\n",
    "+    *export_file**: If false return as pd dataframe\n",
    "+    *write_dir**: path where to write the dataset to if save_file = True\n",
    "+    *network**: Yeo7 or Yeo17 network (only applicable if preprocessing_type = aggregation)\n",
    "+    *statistic**: Summary statistic to be applied (only applicable if preprocessing_type = aggregation)\n",
    "+    *upper**: boolean whether only upper diagonal elements of connecivity matrices should be used\n",
    "+    *file_format**: Pass \"h5\" for further modelling in python or \"csv\" for R (default \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2840,
     "status": "ok",
     "timestamp": 1645194398205,
     "user": {
      "displayName": "Jonas Klingele",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01851783090542566825"
     },
     "user_tz": -60
    },
    "id": "TVio-2b3OjCQ",
    "outputId": "848bd468-3749-47f3-e89b-6eb03c491021"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1645194596416,
     "user": {
      "displayName": "Jonas Klingele",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01851783090542566825"
     },
     "user_tz": -60
    },
    "id": "JFRC1BcHfzo5"
   },
   "outputs": [],
   "source": [
    "from connectome.preprocessing.preprocessing_matlab_files import preprocess_mat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1645194992214,
     "user": {
      "displayName": "Jonas Klingele",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01851783090542566825"
     },
     "user_tz": -60
    },
    "id": "54xpo4usfzo6"
   },
   "outputs": [],
   "source": [
    "matlab_dir = r\"path/to/matlab/files\" # Enter the directory for the matlab files\n",
    "excel_path = r\"path/to/excel/sheet.xlsxx\" # Enter the directory for the corresponding excel sheet\n",
    "preprocessing_type = 'aggregation'\n",
    "write_dir = \"\" # ...\n",
    "export_file = False # rename to export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQMLPvI_fzo6"
   },
   "outputs": [],
   "source": [
    "df = preprocess_mat_files(matlab_dir = matlab_dir, excel_path = excel_path, preprocessing_type = preprocessing_type,\n",
    "                          write_dir = write_dir, export_file = export_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgNDTjc3fzo7"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GesXXX0sfzo7"
   },
   "source": [
    "## 2. Modelling\n",
    "\n",
    "In the second step, you can decide between running the new input files on a pretrained model or train a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIU_ujK1fzo7"
   },
   "source": [
    "### 2.1  Data preparation\n",
    "Preparation of the data for modelling. Creates the target variable, drops unnecessary columns, performs a train/test split (if wanted). \\\\\n",
    "The user has to specify:\n",
    "- *classification*: is it a classification task (True) or a regression task (False)\n",
    "- *columns_drop*: which variables shoulnd't be used for modelling\n",
    "- *target*: what is the name of the target variable\n",
    "- *y_0, y_1* (only relevant for classification task): which values of the target variable are 0, which are 1\n",
    "- *train_size*: size of the training data\n",
    "- *seed*: a seed to ensure reproducibility of train/test split\n",
    "- split: should a train/test split be performed or not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8RM0TUufzo7"
   },
   "outputs": [],
   "source": [
    "from connectome.preprocessing.data_preparation import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTSdzorufzo7"
   },
   "outputs": [],
   "source": [
    "classification = True\n",
    "columns_drop = [\"ConnID\", \"Repseudonym\", \"siteid\", \"visdat\", \"MEM_score\", \"Apoe\", \"IDs\"]\n",
    "target = \"prmdiag\"\n",
    "y_0 = [0]\n",
    "y_1 = [2, 3]\n",
    "train_size = 0.8\n",
    "seed = 1855\n",
    "split = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIi5_9ATgTS4"
   },
   "outputs": [],
   "source": [
    "# preparation of data\n",
    "X_train, y_train, X_test, y_test = prepare_data(data = df, classification = classification,\n",
    "                                                columns_drop = columns_drop, target = target, y_0 = y_0, y_1 = y_1,\n",
    "                                                train_size = train_size, seed = seed, split = split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX99AfITfzo8"
   },
   "source": [
    "### 2.2 Run Model or get pretrained model\n",
    "\n",
    "Selection which model should be used and whether a pretrained model or newly trained model is desired.\n",
    "\n",
    "You can find a selection fo pretrained models under the models folder.\n",
    "\n",
    "The user has to specify:\n",
    "- X_train: training data coming from the previous step\n",
    "- y_train: values of target variable for the training data coming from the previous step\n",
    "- model: which model should be used (options are: \"elnet\" for elastic net, \"gboost\" for gradient boosting, \"rf\" for random forest and \"cnn\" for convolutional neural network)\n",
    "- pretrained: is a pretrained model wanted or should the training data be used to fit a new one. (True = pretrained, False = new fit)\n",
    "- model_path: the full path to the desired pretrained model if one should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaJOVUgNfzo8",
    "outputId": "eed84514-09c7-4c74-e8cf-4359da2b57a4"
   },
   "outputs": [],
   "source": [
    "from connectome.models.framework import model_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_framework(X_train = X_train,\n",
    "                        y_train = y_train,\n",
    "                        model = \"gboost\",\n",
    "                        pretrained = False,\n",
    "                        model_path = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnxI8ZWEfzo8"
   },
   "source": [
    "## 3. Model Evaluation\n",
    "\n",
    "In this step you can now evaluate the Model on a set of prespecified metrics.\n",
    "\n",
    "+ For Classification: Accuracy, Precision, Recall, F1 and AUC\n",
    "+ For Regression: MSE, MAE and R2\n",
    "\n",
    "Checkout https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m20cNjWqfzo8"
   },
   "outputs": [],
   "source": [
    "from connectome.models.evaluation import model_evaluation\n",
    "from connectome.models.brainnet_cnn import preprocess_test_data_for_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a cnn Model was trained uncomment the next line to transform the test_dataset to the right input format for the CNN with the same settings\n",
    "# X_test, y_test = preprocess_test_data_for_cnn(X_test, y_test, aggregation=False, reorder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tymSZ5sefzo8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_evaluation(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UY8r5oMVfzo8"
   },
   "source": [
    "## 4. Feature Visualization and Interpretation\n",
    "\n",
    "In the final step you can choose between several feature visualization and interpretation techniques.\n",
    "\n",
    "The user has to specify:\n",
    "+        model: the model from  step 2\n",
    "+        X: X_test dataframe\n",
    "+        y: Target test dataframe\n",
    "+        viz_method: Choice  of \"GFI\" , \"GFI_only\", \"FI\" , \"FI_only\", \"elastic_net\", \"shapley\" and \"feature_attribution\"\n",
    "\n",
    "Visualization methods:\n",
    "+ GFI: Grouped Permutation Feature Importance (based on yeo7 network)\n",
    "+ GFI_only: Group only Permutation Feature Importance (based on yeo7 network)\n",
    "+ FI: Permutation Feature Importance\n",
    "+ FI_only: Version of Group only Permutation Feature Importance but for every feature, not groups\n",
    "+ elastic_net: Visualization of the elastic net coefficients\n",
    "+ shapley: Summary plot for shapley values\n",
    "+ feature_attribution: Neural Network Visulization with Saliency Maps\n",
    "\n",
    "For more details and customization of plots see our documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii5PDl5efzo8"
   },
   "outputs": [],
   "source": [
    "from connectome.visualization.viz_framework import visualization_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5FzFtovfzo8"
   },
   "outputs": [],
   "source": [
    "viz = visualization_framework(model=model,X=X_test,\n",
    "                              y=y_test, viz_method=\"feature_attribution\", method='saliency', average=True, ordered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Connectome Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
