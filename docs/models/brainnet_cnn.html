<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>src.models.brainnet_cnn API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.models.brainnet_cnn</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd
import random

import keras
import tensorflow as tf
from keras.models import Sequential, Model, Input
from keras.layers import Dense, Dropout, Flatten, Concatenate, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from sklearn.preprocessing import StandardScaler
from keras.layers.advanced_activations import LeakyReLU
from tensorflow.keras.optimizers import Adam, Nadam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.callbacks import EarlyStopping

import src.preprocessing.data_loader as dtl
from src.preprocessing.reorder_matrices_regions import reorder_matrices_regions
from src.preprocessing.data_loader import flat_to_mat_aggregation
from src.models.E2E_conv import E2E_conv


def model_brainnet_cnn(X, y, aggregation=False, reorder=False, augmentation=False, scale=.04, augm_fact=5,
                       batch_size=32, epochs=400, patience=5, validation_size=.2,
                       E2E_filter: int = 32, E2N_filter: int = 48, N2G_tiler: int = 64,
                       dense_filter: int = 64, dropout_rate=0.5,
                       kernel_regularizer=keras.regularizers.l2(0.01),
                       kernel_initializer=&#39;he_uniform&#39;, optimizer=Adam(), activation=&#39;relu&#39;,
                       loss=&#34;binary_crossentropy&#34;
                       ):
    &#34;&#34;&#34;
    Trains a Convolutional Neural Network model based on the design by Kawahara et al. (2016)
    http://doi.org/10.1016/j.neuroimage.2016.09.046.

    Args:
        X: The training dataset
        y: The true labels
        aggregation: Boolean, whether the matrices were aggregated based on yeo7
        reorder:  Boolean, whether to reorder the matrices based on the yeo7 network. (True is recommended when training
            with Brainnetome data. Only applicable to data based on the brainnetome atlas.
        augmentation: Boolean, whether to apply data augmentation to increase the training data size
        scale: Standard deviation of the random noise to be applied for data augmentation
        augm_fact: Augmentation factor, Size of train dataset = original train dataset + augm_fact * noise dataset
        batch_size: number of samples that will be propagated through the network
        epochs: Number of training iterations
        patience: Number of iterations to early stop if no improvement occurs
        validation_size: Size of the validation set to evaluate during training
        E2E_filter: Number of E2E filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        E2N_filter: Number of E2N filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        N2G_tiler: Number of N2G filters , for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        dense_filter: Dense layer size, default 64
        dropout_rate: Size of nodes to randomly drop during training, default .5
        kernel_regularizer: Layer weight regularizers to be applied, default l2 regularization
        kernel_initializer: Kernel initilization strategy, default he_uniform
        optimizer: Method to train the model, default Adam
        activation: Hidden layer activation, default relu
        loss: loss function, default binary_crossentropy
    Returns:
        A fitted neural network model
    &#34;&#34;&#34;

    assert isinstance(aggregation, bool), &#34;invalid datatype for argument aggregation&#34;
    assert isinstance(reorder, bool), &#34;invalid datatype for argument reorder&#34;
    assert isinstance(augmentation, bool), &#34;invalid datatype for argument augmentation&#34;
    assert isinstance(scale, float) &amp; (scale &gt;= 0.0), &#34;invalid path datatype for argument scale or smaller than 0&#34;
    assert isinstance(augm_fact, int) &amp; (
            augm_fact &gt;= 1), &#34;invalid datatype for argument augm_fact or not greater than 1&#34;
    assert isinstance(epochs, int) &amp; (
            epochs &gt;= 1), &#34;invalid datatype for epochs or not greater than 1&#34;
    assert isinstance(patience, int) &amp; (
            patience &gt;= 1), &#34;invalid datatype for argument patience or not greater than 1&#34;
    assert isinstance(validation_size, float) &amp; (validation_size &gt;= 0.0) &amp; \
           (validation_size &lt;= 1.0), &#34;invalid value validation_size&#34;
    assert isinstance(E2E_filter, int) &amp; (
            E2E_filter &gt;= 1), &#34;invalid datatype for argument E2E_filter or not greater than 1&#34;
    assert isinstance(E2N_filter, int) &amp; (
            E2N_filter &gt;= 1), &#34;invalid datatype for argument E2N_filter or not greater than 1&#34;
    assert isinstance(N2G_tiler, int) &amp; (
            N2G_tiler &gt;= 1), &#34;invalid datatype for argument N2G_tiler or not greater than 1&#34;
    assert isinstance(dense_filter, int) &amp; (
            dense_filter &gt;= 1), &#34;invalid datatype for argument dense_filter or not greater than 1&#34;
    assert isinstance(dropout_rate, float) &amp; (dropout_rate &gt;= 0.0) &amp; \
           (dropout_rate &lt;= 1.0), &#34;invalid value dropout_rate&#34;

    # add all possible parameters of brainnet
    X_train, X_train_struc, y_train = preprocess_for_cnn(X, y, aggregation=aggregation, reorder=reorder,
                                                         augmentation=augmentation,
                                                         scale=scale, augmentation_factor=augm_fact)

    # create validation set
    # Train val split
    shuffled_indices = list(range(len(X_train)))
    random.shuffle(shuffled_indices)

    val_ind = int(np.round(len(X_train) * validation_size))
    val_idxs = shuffled_indices[:val_ind]
    train_idxs = shuffled_indices[val_ind:]

    # validation set
    val_x = X_train[val_idxs]
    val_x_struc = X_train_struc[val_idxs]
    val_y = y_train[val_idxs]
    # train set
    train_x = X_train[train_idxs]
    train_x_struc = X_train_struc[train_idxs]
    train_y = y_train[train_idxs]

    # mode input dimension
    input_img_dim = (X_train.shape[1], X_train.shape[2], 1)
    input_struc_dim = (X_train_struc.shape[1])

    print(&#39;Strating to train Model&#39;)
    # Initialize neural network model
    brainnetcnn = brain_net_cnn(input_dim_img=input_img_dim, input_dim_struc=input_struc_dim, output_dim=1,
                                E2E_filter=E2E_filter, E2N_filter=E2N_filter, N2G_tiler=N2G_tiler,
                                dense_filter=dense_filter, dropout_rate=dropout_rate,
                                kernel_regularizer=kernel_regularizer,
                                kernel_initializer=kernel_initializer, opt=optimizer, activation=activation,
                                loss=loss)

    callback = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, patience=patience)

    if input_struc_dim != 0:
        brainnetcnn.fit([train_x, train_x_struc], train_y, epochs=epochs, batch_size=batch_size, verbose=1,
                        validation_data=([val_x, val_x_struc], val_y), callbacks=[callback])
    else:
        brainnetcnn.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1,
                        validation_data=(val_x, val_y), callbacks=[callback])
    return brainnetcnn


def preprocess_for_cnn(X, y, aggregation=False, reorder=False, augmentation=False, scale=.07, augmentation_factor=5):
    &#34;&#34;&#34;
    Prepares and reformats the data for the cnn tensorflow mpde;

    Args:
        X: The training dataset
        y: The true labels
        aggregation: Boolean,whether the matrices were aggregated based on yeo7
        reorder: Boolean, whether to reorder the matrices based on the yeo7 network. Only applicable to data
            based on the brainnetome atlas.
        augmentation: Boolean, whether to apply data augmentation to increase the training data size
        scale: Standard deviation of the random noise to be applied for data augmentation
        augmentation_factor: Augmentation factor, Size of train dataset = original dataset + augm_fact * noise dataset
    Returns:
        X_img: symmetric np.array with the connectivity matrices
        X_struc: np.array with structural information such as e.g. age etc.
        y: dataset labels
    &#34;&#34;&#34;
    assert isinstance(aggregation, bool), &#34;invalid datatype for argument aggregation&#34;
    assert isinstance(reorder, bool), &#34;invalid datatype for argument reorder&#34;
    assert isinstance(augmentation, bool), &#34;invalid datatype for argument augmentation&#34;
    assert isinstance(scale, float) &amp; (scale &gt;= 0.0), &#34;invalid path datatype for argument scale or smaller than 0&#34;
    assert isinstance(augmentation_factor, int) &amp; (
            augmentation_factor &gt;= 1), &#34;invalid datatype for argument augm_fact or not greater than 1&#34;

    # append the connectivity matrix cols to X_img_cols and the rest to X_struc_cols
    X_img_cols = []
    X_struc_cols = []
    for x in X.columns:
        if len(x.split(&#34;_&#34;)) &gt; 1 and x.split(&#34;_&#34;)[0].isdigit() and x.split(&#34;_&#34;)[1].isdigit():
            X_img_cols.append(x)
        else:
            X_struc_cols.append(x)

    # apply data augmentation
    if augmentation:
        print(&#34;Starting Data Augmentation&#34;)
        X_img_aug, X_struc_aug, y_aug = augmented_data(X, y, X_img_cols, X_struc_cols, sd=scale,
                                                       augm_fact=augmentation_factor)
        # merging augmented data with input data
        X_img = pd.concat([X[X_img_cols], X_img_aug])
        X_struc = pd.concat([X[X_struc_cols], X_struc_aug])
        y = np.concatenate([np.array(y), y_aug], axis=0)
    else:
        X_img = X[X_img_cols]
        X_struc = X[X_struc_cols]
        y = np.array(y)

    print(&#34;Turning flat array to matrix&#34;)
    # turn flat array to matrix
    if aggregation:
        n_c = 8
        n_train = len(X_img)
        X_train_2d = np.zeros(n_train * n_c * n_c).reshape(n_train, n_c, n_c)

        # turn array to matrix
        for i in range(n_train):
            X_train_2d[i] = flat_to_mat_aggregation(X_img.iloc[i, :])

        stacked = np.stack(X_train_2d, axis=0)

    else:
        n_c = dtl.flat_to_mat(X_img.iloc[0, :]).shape[0]
        n_train = len(X_img)
        X_train_2d = np.zeros(n_train * n_c * n_c).reshape(n_train, n_c, n_c)

        # turn array to matrix
        for i in range(n_train):
            X_train_2d[i] = dtl.flat_to_mat(X_img.iloc[i, :])

        if reorder:
            stacked = np.stack(reorder_matrices_regions(X_train_2d, network=&#39;yeo7&#39;), axis=0)
        else:
            stacked = np.stack(X_train_2d, axis=0)

    # reshape data for the convolutional neural network
    X_img = stacked.reshape(stacked.shape[0], stacked.shape[1], stacked.shape[2], 1)
    if X_struc.shape[1] != 0:
        X_struc = X_struc.to_numpy().reshape(stacked.shape[0], 3)
    else:
        X_struc = X_struc.to_numpy()

    return X_img, X_struc, y


def brain_net_cnn(input_dim_img, input_dim_struc, output_dim: int = 1,
                  E2E_filter: int = 32, E2N_filter: int = 48, N2G_tiler: int = 64,
                  dense_filter: int = 64, dropout_rate=0.5,
                  kernel_regularizer=keras.regularizers.l2(0.01),
                  kernel_initializer=&#39;he_uniform&#39;, opt=Adam(), activation=&#39;relu&#39;,
                  loss=&#34;binary_crossentropy&#34;):
    &#34;&#34;&#34;
    Trains a Convolutional Neural Network model based on the design by Kawahara et al. (2016)
    http://doi.org/10.1016/j.neuroimage.2016.09.046.

    Args:
        input_dim_img: Input dimension of the connectivity matrices
        input_dim_struc: Input dimension of the structural information
        output_dim: Output dimension for the neural network
        E2E_filter: Number of E2E filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        E2N_filter: Number of E2N filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        N2G_tiler: Number of N2G filters , for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        dense_filter: Dense layer size, default 64
        dropout_rate: Size of nodes to randomly drop during training, default .5
        kernel_regularizer: Layer weight regularizers to be applied, default l2 regularization
        kernel_initializer: Kernel initilization strategy, default he_uniform
        optimizer: Method to train the model, default Adam
        activation: Hidden layer activation, default relu
        loss: loss function, default binary_crossentropy
    Returns:
        A fitted neural network model
    &#34;&#34;&#34;
    assert isinstance(output_dim, int) &amp; (
            output_dim == 1), &#34;invalid datatype for argument output_dim or not equal to 1&#34;
    assert isinstance(E2E_filter, int) &amp; (
            E2E_filter &gt;= 1), &#34;invalid datatype for argument E2E_filter or not greater than 1&#34;
    assert isinstance(E2N_filter, int) &amp; (
            E2N_filter &gt;= 1), &#34;invalid datatype for argument E2N_filter or not greater than 1&#34;
    assert isinstance(N2G_tiler, int) &amp; (
            N2G_tiler &gt;= 1), &#34;invalid datatype for argument N2G_tiler or not greater than 1&#34;
    assert isinstance(dense_filter, int) &amp; (
            dense_filter &gt;= 1), &#34;invalid datatype for argument dense_filter or not greater than 1&#34;
    assert isinstance(dropout_rate, float) &amp; (dropout_rate &gt;= 0.0) &amp; \
           (dropout_rate &lt;= 1.0), &#34;invalid value dropout_rate&#34;

    # we have connectivity matrices as input + structural inputs such as e.g. age, sex etc.
    if input_dim_struc != 0:
        input_img = Input(shape=input_dim_img, name=&#39;input_img&#39;)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(input_img)
        x = BatchNormalization()(x)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=E2N_filter, kernel_size=(1, input_dim_img[0]), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Edge-to-Node&#39;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=N2G_tiler, kernel_size=(input_dim_img[1], 1), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Node-to-Graph&#39;)(x)

        x = Dropout(dropout_rate)(x)
        x = Flatten()(x)

        # add strutural data such as age, etc.
        input_struc = Input(shape=input_dim_struc, name=&#39;input_struc&#39;)

        x = Concatenate(axis=-1)([x, input_struc])

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        out = Dense(output_dim, activation=&#34;sigmoid&#34;)(x)

        # compile model
        model = Model(inputs=[input_img, input_struc], outputs=out, name=&#39;BrainNetCNN&#39;)

    else:
        # we have only connectivity matrices as input
        input_img = Input(shape=input_dim_img, name=&#39;input_img&#39;)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(input_img)
        x = BatchNormalization()(x)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=E2N_filter, kernel_size=(1, input_dim_img[0]), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Edge-to-Node&#39;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=N2G_tiler, kernel_size=(input_dim_img[1], 1), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Node-to-Graph&#39;)(x)

        x = Dropout(dropout_rate)(x)
        x = Flatten()(x)

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        out = Dense(output_dim, activation=&#34;sigmoid&#34;)(x)

        # compile model
        model = Model(inputs=[input_img], outputs=out, name=&#39;BrainNetCNN&#39;)

    model.compile(loss=loss,
                  optimizer=opt,
                  metrics=[tf.keras.metrics.BinaryAccuracy(),
                           tf.keras.metrics.FalseNegatives()])

    return model


def augmented_data(x: pd.DataFrame, y: pd.Series, X_img_cols: list, X_struc_cols: list, sd=0.17, augm_fact=5):
    &#34;&#34;&#34;
    Applies data augmentation to an input dataframe

    Args:
        x: input dataframe to be augmented
        y: labels
        aggregation: Boolean, whether the matrices were aggregated based on yeo7
        reorder:  Boolean, whether to reorder the matrices based on the yeo7 network. (True is recommended when training
            with Brainnetome data. Only applicable to data based on the brainnetome atlas.
        sd: Standard deviation of the random noise to be applied for data augmentation
        augm_fact: Augmentation factor, Size of train dataset = original train dataset + augm_fact * noise dataset:

    Returns:
        x_aug: augmented connectivity matrices
        x_struc_aug: augmented structural information such as e.g. age etc.
        y_aug: augmented dataset labels
    &#34;&#34;&#34;

    x_aug = np.array(x[X_img_cols].copy())
    noise = np.random.normal(
        scale=sd,
        size=x_aug.shape[0] * x_aug.shape[1] * augm_fact).reshape(
        x_aug.shape[0] * augm_fact, x_aug.shape[1])
    x_aug = np.vstack([x_aug] * augm_fact) + noise
    x_struc_aug = np.vstack([np.array(x[X_struc_cols])] * augm_fact)
    y_aug = np.hstack([np.array(y)] * augm_fact)

    return pd.DataFrame(x_aug, columns=X_img_cols), pd.DataFrame(x_struc_aug, columns=X_struc_cols), y_aug


def preprocess_test_data_for_cnn(X_test, y_test, aggregation=False, reorder=False):
    &#34;&#34;&#34;
    Preprares the test dataset for evaluation

    Args:
        x: test dataframe
        y: labels
        aggregation: List of colnames of the connectivity matrix columns
        reorder: List of colnames of the structural columns

    Returns:
        Test dataframe and labels. The test dataframe is returned as list if structrual information exists.
    &#34;&#34;&#34;
    assert isinstance(aggregation, bool), &#34;invalid datatype for argument aggregation&#34;
    assert isinstance(reorder, bool), &#34;invalid datatype for argument reorder&#34;

    X_test_img, X_test_struc, y_test = preprocess_for_cnn(X_test, y_test, aggregation=aggregation, reorder=reorder,
                                                          augmentation=False)

    # we have only connectivity matrices as input
    if X_test_struc.shape[1] == 0:
        return X_test_img, y_test
    # we have connectivity matrices as + structural information input
    else:
        return [X_test_img, X_test_struc], y_test</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.models.brainnet_cnn.augmented_data"><code class="name flex">
<span>def <span class="ident">augmented_data</span></span>(<span>x: pandas.core.frame.DataFrame, y: pandas.core.series.Series, X_img_cols: list, X_struc_cols: list, sd=0.17, augm_fact=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies data augmentation to an input dataframe</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>input dataframe to be augmented</dd>
<dt><strong><code>y</code></strong></dt>
<dd>labels</dd>
<dt><strong><code>aggregation</code></strong></dt>
<dd>Boolean, whether the matrices were aggregated based on yeo7</dd>
<dt><strong><code>reorder</code></strong></dt>
<dd>Boolean, whether to reorder the matrices based on the yeo7 network. (True is recommended when training
with Brainnetome data. Only applicable to data based on the brainnetome atlas.</dd>
<dt><strong><code>sd</code></strong></dt>
<dd>Standard deviation of the random noise to be applied for data augmentation</dd>
<dt><strong><code>augm_fact</code></strong></dt>
<dd>Augmentation factor, Size of train dataset = original train dataset + augm_fact * noise dataset:</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>x_aug</code></dt>
<dd>augmented connectivity matrices</dd>
<dt><code>x_struc_aug</code></dt>
<dd>augmented structural information such as e.g. age etc.</dd>
<dt><code>y_aug</code></dt>
<dd>augmented dataset labels</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def augmented_data(x: pd.DataFrame, y: pd.Series, X_img_cols: list, X_struc_cols: list, sd=0.17, augm_fact=5):
    &#34;&#34;&#34;
    Applies data augmentation to an input dataframe

    Args:
        x: input dataframe to be augmented
        y: labels
        aggregation: Boolean, whether the matrices were aggregated based on yeo7
        reorder:  Boolean, whether to reorder the matrices based on the yeo7 network. (True is recommended when training
            with Brainnetome data. Only applicable to data based on the brainnetome atlas.
        sd: Standard deviation of the random noise to be applied for data augmentation
        augm_fact: Augmentation factor, Size of train dataset = original train dataset + augm_fact * noise dataset:

    Returns:
        x_aug: augmented connectivity matrices
        x_struc_aug: augmented structural information such as e.g. age etc.
        y_aug: augmented dataset labels
    &#34;&#34;&#34;

    x_aug = np.array(x[X_img_cols].copy())
    noise = np.random.normal(
        scale=sd,
        size=x_aug.shape[0] * x_aug.shape[1] * augm_fact).reshape(
        x_aug.shape[0] * augm_fact, x_aug.shape[1])
    x_aug = np.vstack([x_aug] * augm_fact) + noise
    x_struc_aug = np.vstack([np.array(x[X_struc_cols])] * augm_fact)
    y_aug = np.hstack([np.array(y)] * augm_fact)

    return pd.DataFrame(x_aug, columns=X_img_cols), pd.DataFrame(x_struc_aug, columns=X_struc_cols), y_aug</code></pre>
</details>
</dd>
<dt id="src.models.brainnet_cnn.brain_net_cnn"><code class="name flex">
<span>def <span class="ident">brain_net_cnn</span></span>(<span>input_dim_img, input_dim_struc, output_dim: int = 1, E2E_filter: int = 32, E2N_filter: int = 48, N2G_tiler: int = 64, dense_filter: int = 64, dropout_rate=0.5, kernel_regularizer=&lt;keras.regularizers.L2 object&gt;, kernel_initializer='he_uniform', opt=&lt;keras.optimizer_v2.adam.Adam object&gt;, activation='relu', loss='binary_crossentropy')</span>
</code></dt>
<dd>
<div class="desc"><p>Trains a Convolutional Neural Network model based on the design by Kawahara et al. (2016)
<a href="http://doi.org/10.1016/j.neuroimage.2016.09.046.">http://doi.org/10.1016/j.neuroimage.2016.09.046.</a></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_dim_img</code></strong></dt>
<dd>Input dimension of the connectivity matrices</dd>
<dt><strong><code>input_dim_struc</code></strong></dt>
<dd>Input dimension of the structural information</dd>
<dt><strong><code>output_dim</code></strong></dt>
<dd>Output dimension for the neural network</dd>
<dt><strong><code>E2E_filter</code></strong></dt>
<dd>Number of E2E filters, for a detailed description check out:
<a href="https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/">https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/</a></dd>
<dt><strong><code>E2N_filter</code></strong></dt>
<dd>Number of E2N filters, for a detailed description check out:
<a href="https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/">https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/</a></dd>
<dt><strong><code>N2G_tiler</code></strong></dt>
<dd>Number of N2G filters , for a detailed description check out:
<a href="https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/">https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/</a></dd>
<dt><strong><code>dense_filter</code></strong></dt>
<dd>Dense layer size, default 64</dd>
<dt><strong><code>dropout_rate</code></strong></dt>
<dd>Size of nodes to randomly drop during training, default .5</dd>
<dt><strong><code>kernel_regularizer</code></strong></dt>
<dd>Layer weight regularizers to be applied, default l2 regularization</dd>
<dt><strong><code>kernel_initializer</code></strong></dt>
<dd>Kernel initilization strategy, default he_uniform</dd>
<dt><strong><code>optimizer</code></strong></dt>
<dd>Method to train the model, default Adam</dd>
<dt><strong><code>activation</code></strong></dt>
<dd>Hidden layer activation, default relu</dd>
<dt><strong><code>loss</code></strong></dt>
<dd>loss function, default binary_crossentropy</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A fitted neural network model</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def brain_net_cnn(input_dim_img, input_dim_struc, output_dim: int = 1,
                  E2E_filter: int = 32, E2N_filter: int = 48, N2G_tiler: int = 64,
                  dense_filter: int = 64, dropout_rate=0.5,
                  kernel_regularizer=keras.regularizers.l2(0.01),
                  kernel_initializer=&#39;he_uniform&#39;, opt=Adam(), activation=&#39;relu&#39;,
                  loss=&#34;binary_crossentropy&#34;):
    &#34;&#34;&#34;
    Trains a Convolutional Neural Network model based on the design by Kawahara et al. (2016)
    http://doi.org/10.1016/j.neuroimage.2016.09.046.

    Args:
        input_dim_img: Input dimension of the connectivity matrices
        input_dim_struc: Input dimension of the structural information
        output_dim: Output dimension for the neural network
        E2E_filter: Number of E2E filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        E2N_filter: Number of E2N filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        N2G_tiler: Number of N2G filters , for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        dense_filter: Dense layer size, default 64
        dropout_rate: Size of nodes to randomly drop during training, default .5
        kernel_regularizer: Layer weight regularizers to be applied, default l2 regularization
        kernel_initializer: Kernel initilization strategy, default he_uniform
        optimizer: Method to train the model, default Adam
        activation: Hidden layer activation, default relu
        loss: loss function, default binary_crossentropy
    Returns:
        A fitted neural network model
    &#34;&#34;&#34;
    assert isinstance(output_dim, int) &amp; (
            output_dim == 1), &#34;invalid datatype for argument output_dim or not equal to 1&#34;
    assert isinstance(E2E_filter, int) &amp; (
            E2E_filter &gt;= 1), &#34;invalid datatype for argument E2E_filter or not greater than 1&#34;
    assert isinstance(E2N_filter, int) &amp; (
            E2N_filter &gt;= 1), &#34;invalid datatype for argument E2N_filter or not greater than 1&#34;
    assert isinstance(N2G_tiler, int) &amp; (
            N2G_tiler &gt;= 1), &#34;invalid datatype for argument N2G_tiler or not greater than 1&#34;
    assert isinstance(dense_filter, int) &amp; (
            dense_filter &gt;= 1), &#34;invalid datatype for argument dense_filter or not greater than 1&#34;
    assert isinstance(dropout_rate, float) &amp; (dropout_rate &gt;= 0.0) &amp; \
           (dropout_rate &lt;= 1.0), &#34;invalid value dropout_rate&#34;

    # we have connectivity matrices as input + structural inputs such as e.g. age, sex etc.
    if input_dim_struc != 0:
        input_img = Input(shape=input_dim_img, name=&#39;input_img&#39;)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(input_img)
        x = BatchNormalization()(x)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=E2N_filter, kernel_size=(1, input_dim_img[0]), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Edge-to-Node&#39;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=N2G_tiler, kernel_size=(input_dim_img[1], 1), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Node-to-Graph&#39;)(x)

        x = Dropout(dropout_rate)(x)
        x = Flatten()(x)

        # add strutural data such as age, etc.
        input_struc = Input(shape=input_dim_struc, name=&#39;input_struc&#39;)

        x = Concatenate(axis=-1)([x, input_struc])

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        out = Dense(output_dim, activation=&#34;sigmoid&#34;)(x)

        # compile model
        model = Model(inputs=[input_img, input_struc], outputs=out, name=&#39;BrainNetCNN&#39;)

    else:
        # we have only connectivity matrices as input
        input_img = Input(shape=input_dim_img, name=&#39;input_img&#39;)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(input_img)
        x = BatchNormalization()(x)

        x = E2E_conv(rank=2, filters=E2E_filter, kernel_size=(2, input_dim_img[0]),
                     kernel_regularizer=kernel_regularizer,
                     input_shape=(input_dim_img[0], input_dim_img[1], input_dim_img[2]),
                     activation=activation, data_format=&#34;channels_last&#34;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=E2N_filter, kernel_size=(1, input_dim_img[0]), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Edge-to-Node&#39;)(x)

        x = BatchNormalization()(x)
        x = Conv2D(filters=N2G_tiler, kernel_size=(input_dim_img[1], 1), strides=(1, 1),
                   padding=&#39;valid&#39;,
                   kernel_regularizer=kernel_regularizer,
                   kernel_initializer=kernel_initializer, activation=activation, name=&#39;Node-to-Graph&#39;)(x)

        x = Dropout(dropout_rate)(x)
        x = Flatten()(x)

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        x = Dense(dense_filter, kernel_initializer=kernel_initializer, activation=activation)(x)
        x = Dropout(dropout_rate)(x)

        out = Dense(output_dim, activation=&#34;sigmoid&#34;)(x)

        # compile model
        model = Model(inputs=[input_img], outputs=out, name=&#39;BrainNetCNN&#39;)

    model.compile(loss=loss,
                  optimizer=opt,
                  metrics=[tf.keras.metrics.BinaryAccuracy(),
                           tf.keras.metrics.FalseNegatives()])

    return model</code></pre>
</details>
</dd>
<dt id="src.models.brainnet_cnn.model_brainnet_cnn"><code class="name flex">
<span>def <span class="ident">model_brainnet_cnn</span></span>(<span>X, y, aggregation=False, reorder=False, augmentation=False, scale=0.04, augm_fact=5, batch_size=32, epochs=400, patience=5, validation_size=0.2, E2E_filter: int = 32, E2N_filter: int = 48, N2G_tiler: int = 64, dense_filter: int = 64, dropout_rate=0.5, kernel_regularizer=&lt;keras.regularizers.L2 object&gt;, kernel_initializer='he_uniform', optimizer=&lt;keras.optimizer_v2.adam.Adam object&gt;, activation='relu', loss='binary_crossentropy')</span>
</code></dt>
<dd>
<div class="desc"><p>Trains a Convolutional Neural Network model based on the design by Kawahara et al. (2016)
<a href="http://doi.org/10.1016/j.neuroimage.2016.09.046.">http://doi.org/10.1016/j.neuroimage.2016.09.046.</a></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong></dt>
<dd>The training dataset</dd>
<dt><strong><code>y</code></strong></dt>
<dd>The true labels</dd>
<dt><strong><code>aggregation</code></strong></dt>
<dd>Boolean, whether the matrices were aggregated based on yeo7</dd>
<dt><strong><code>reorder</code></strong></dt>
<dd>Boolean, whether to reorder the matrices based on the yeo7 network. (True is recommended when training
with Brainnetome data. Only applicable to data based on the brainnetome atlas.</dd>
<dt><strong><code>augmentation</code></strong></dt>
<dd>Boolean, whether to apply data augmentation to increase the training data size</dd>
<dt><strong><code>scale</code></strong></dt>
<dd>Standard deviation of the random noise to be applied for data augmentation</dd>
<dt><strong><code>augm_fact</code></strong></dt>
<dd>Augmentation factor, Size of train dataset = original train dataset + augm_fact * noise dataset</dd>
<dt><strong><code>batch_size</code></strong></dt>
<dd>number of samples that will be propagated through the network</dd>
<dt><strong><code>epochs</code></strong></dt>
<dd>Number of training iterations</dd>
<dt><strong><code>patience</code></strong></dt>
<dd>Number of iterations to early stop if no improvement occurs</dd>
<dt><strong><code>validation_size</code></strong></dt>
<dd>Size of the validation set to evaluate during training</dd>
<dt><strong><code>E2E_filter</code></strong></dt>
<dd>Number of E2E filters, for a detailed description check out:
<a href="https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/">https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/</a></dd>
<dt><strong><code>E2N_filter</code></strong></dt>
<dd>Number of E2N filters, for a detailed description check out:
<a href="https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/">https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/</a></dd>
<dt><strong><code>N2G_tiler</code></strong></dt>
<dd>Number of N2G filters , for a detailed description check out:
<a href="https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/">https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/</a></dd>
<dt><strong><code>dense_filter</code></strong></dt>
<dd>Dense layer size, default 64</dd>
<dt><strong><code>dropout_rate</code></strong></dt>
<dd>Size of nodes to randomly drop during training, default .5</dd>
<dt><strong><code>kernel_regularizer</code></strong></dt>
<dd>Layer weight regularizers to be applied, default l2 regularization</dd>
<dt><strong><code>kernel_initializer</code></strong></dt>
<dd>Kernel initilization strategy, default he_uniform</dd>
<dt><strong><code>optimizer</code></strong></dt>
<dd>Method to train the model, default Adam</dd>
<dt><strong><code>activation</code></strong></dt>
<dd>Hidden layer activation, default relu</dd>
<dt><strong><code>loss</code></strong></dt>
<dd>loss function, default binary_crossentropy</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A fitted neural network model</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def model_brainnet_cnn(X, y, aggregation=False, reorder=False, augmentation=False, scale=.04, augm_fact=5,
                       batch_size=32, epochs=400, patience=5, validation_size=.2,
                       E2E_filter: int = 32, E2N_filter: int = 48, N2G_tiler: int = 64,
                       dense_filter: int = 64, dropout_rate=0.5,
                       kernel_regularizer=keras.regularizers.l2(0.01),
                       kernel_initializer=&#39;he_uniform&#39;, optimizer=Adam(), activation=&#39;relu&#39;,
                       loss=&#34;binary_crossentropy&#34;
                       ):
    &#34;&#34;&#34;
    Trains a Convolutional Neural Network model based on the design by Kawahara et al. (2016)
    http://doi.org/10.1016/j.neuroimage.2016.09.046.

    Args:
        X: The training dataset
        y: The true labels
        aggregation: Boolean, whether the matrices were aggregated based on yeo7
        reorder:  Boolean, whether to reorder the matrices based on the yeo7 network. (True is recommended when training
            with Brainnetome data. Only applicable to data based on the brainnetome atlas.
        augmentation: Boolean, whether to apply data augmentation to increase the training data size
        scale: Standard deviation of the random noise to be applied for data augmentation
        augm_fact: Augmentation factor, Size of train dataset = original train dataset + augm_fact * noise dataset
        batch_size: number of samples that will be propagated through the network
        epochs: Number of training iterations
        patience: Number of iterations to early stop if no improvement occurs
        validation_size: Size of the validation set to evaluate during training
        E2E_filter: Number of E2E filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        E2N_filter: Number of E2N filters, for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        N2G_tiler: Number of N2G filters , for a detailed description check out:
            https://kawahara.ca/convolutional-neural-networks-for-adjacency-matrices/
        dense_filter: Dense layer size, default 64
        dropout_rate: Size of nodes to randomly drop during training, default .5
        kernel_regularizer: Layer weight regularizers to be applied, default l2 regularization
        kernel_initializer: Kernel initilization strategy, default he_uniform
        optimizer: Method to train the model, default Adam
        activation: Hidden layer activation, default relu
        loss: loss function, default binary_crossentropy
    Returns:
        A fitted neural network model
    &#34;&#34;&#34;

    assert isinstance(aggregation, bool), &#34;invalid datatype for argument aggregation&#34;
    assert isinstance(reorder, bool), &#34;invalid datatype for argument reorder&#34;
    assert isinstance(augmentation, bool), &#34;invalid datatype for argument augmentation&#34;
    assert isinstance(scale, float) &amp; (scale &gt;= 0.0), &#34;invalid path datatype for argument scale or smaller than 0&#34;
    assert isinstance(augm_fact, int) &amp; (
            augm_fact &gt;= 1), &#34;invalid datatype for argument augm_fact or not greater than 1&#34;
    assert isinstance(epochs, int) &amp; (
            epochs &gt;= 1), &#34;invalid datatype for epochs or not greater than 1&#34;
    assert isinstance(patience, int) &amp; (
            patience &gt;= 1), &#34;invalid datatype for argument patience or not greater than 1&#34;
    assert isinstance(validation_size, float) &amp; (validation_size &gt;= 0.0) &amp; \
           (validation_size &lt;= 1.0), &#34;invalid value validation_size&#34;
    assert isinstance(E2E_filter, int) &amp; (
            E2E_filter &gt;= 1), &#34;invalid datatype for argument E2E_filter or not greater than 1&#34;
    assert isinstance(E2N_filter, int) &amp; (
            E2N_filter &gt;= 1), &#34;invalid datatype for argument E2N_filter or not greater than 1&#34;
    assert isinstance(N2G_tiler, int) &amp; (
            N2G_tiler &gt;= 1), &#34;invalid datatype for argument N2G_tiler or not greater than 1&#34;
    assert isinstance(dense_filter, int) &amp; (
            dense_filter &gt;= 1), &#34;invalid datatype for argument dense_filter or not greater than 1&#34;
    assert isinstance(dropout_rate, float) &amp; (dropout_rate &gt;= 0.0) &amp; \
           (dropout_rate &lt;= 1.0), &#34;invalid value dropout_rate&#34;

    # add all possible parameters of brainnet
    X_train, X_train_struc, y_train = preprocess_for_cnn(X, y, aggregation=aggregation, reorder=reorder,
                                                         augmentation=augmentation,
                                                         scale=scale, augmentation_factor=augm_fact)

    # create validation set
    # Train val split
    shuffled_indices = list(range(len(X_train)))
    random.shuffle(shuffled_indices)

    val_ind = int(np.round(len(X_train) * validation_size))
    val_idxs = shuffled_indices[:val_ind]
    train_idxs = shuffled_indices[val_ind:]

    # validation set
    val_x = X_train[val_idxs]
    val_x_struc = X_train_struc[val_idxs]
    val_y = y_train[val_idxs]
    # train set
    train_x = X_train[train_idxs]
    train_x_struc = X_train_struc[train_idxs]
    train_y = y_train[train_idxs]

    # mode input dimension
    input_img_dim = (X_train.shape[1], X_train.shape[2], 1)
    input_struc_dim = (X_train_struc.shape[1])

    print(&#39;Strating to train Model&#39;)
    # Initialize neural network model
    brainnetcnn = brain_net_cnn(input_dim_img=input_img_dim, input_dim_struc=input_struc_dim, output_dim=1,
                                E2E_filter=E2E_filter, E2N_filter=E2N_filter, N2G_tiler=N2G_tiler,
                                dense_filter=dense_filter, dropout_rate=dropout_rate,
                                kernel_regularizer=kernel_regularizer,
                                kernel_initializer=kernel_initializer, opt=optimizer, activation=activation,
                                loss=loss)

    callback = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, patience=patience)

    if input_struc_dim != 0:
        brainnetcnn.fit([train_x, train_x_struc], train_y, epochs=epochs, batch_size=batch_size, verbose=1,
                        validation_data=([val_x, val_x_struc], val_y), callbacks=[callback])
    else:
        brainnetcnn.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1,
                        validation_data=(val_x, val_y), callbacks=[callback])
    return brainnetcnn</code></pre>
</details>
</dd>
<dt id="src.models.brainnet_cnn.preprocess_for_cnn"><code class="name flex">
<span>def <span class="ident">preprocess_for_cnn</span></span>(<span>X, y, aggregation=False, reorder=False, augmentation=False, scale=0.07, augmentation_factor=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepares and reformats the data for the cnn tensorflow mpde;</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong></dt>
<dd>The training dataset</dd>
<dt><strong><code>y</code></strong></dt>
<dd>The true labels</dd>
<dt><strong><code>aggregation</code></strong></dt>
<dd>Boolean,whether the matrices were aggregated based on yeo7</dd>
<dt><strong><code>reorder</code></strong></dt>
<dd>Boolean, whether to reorder the matrices based on the yeo7 network. Only applicable to data
based on the brainnetome atlas.</dd>
<dt><strong><code>augmentation</code></strong></dt>
<dd>Boolean, whether to apply data augmentation to increase the training data size</dd>
<dt><strong><code>scale</code></strong></dt>
<dd>Standard deviation of the random noise to be applied for data augmentation</dd>
<dt><strong><code>augmentation_factor</code></strong></dt>
<dd>Augmentation factor, Size of train dataset = original dataset + augm_fact * noise dataset</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>X_img</code></dt>
<dd>symmetric np.array with the connectivity matrices</dd>
<dt><code>X_struc</code></dt>
<dd>np.array with structural information such as e.g. age etc.</dd>
<dt><code>y</code></dt>
<dd>dataset labels</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_for_cnn(X, y, aggregation=False, reorder=False, augmentation=False, scale=.07, augmentation_factor=5):
    &#34;&#34;&#34;
    Prepares and reformats the data for the cnn tensorflow mpde;

    Args:
        X: The training dataset
        y: The true labels
        aggregation: Boolean,whether the matrices were aggregated based on yeo7
        reorder: Boolean, whether to reorder the matrices based on the yeo7 network. Only applicable to data
            based on the brainnetome atlas.
        augmentation: Boolean, whether to apply data augmentation to increase the training data size
        scale: Standard deviation of the random noise to be applied for data augmentation
        augmentation_factor: Augmentation factor, Size of train dataset = original dataset + augm_fact * noise dataset
    Returns:
        X_img: symmetric np.array with the connectivity matrices
        X_struc: np.array with structural information such as e.g. age etc.
        y: dataset labels
    &#34;&#34;&#34;
    assert isinstance(aggregation, bool), &#34;invalid datatype for argument aggregation&#34;
    assert isinstance(reorder, bool), &#34;invalid datatype for argument reorder&#34;
    assert isinstance(augmentation, bool), &#34;invalid datatype for argument augmentation&#34;
    assert isinstance(scale, float) &amp; (scale &gt;= 0.0), &#34;invalid path datatype for argument scale or smaller than 0&#34;
    assert isinstance(augmentation_factor, int) &amp; (
            augmentation_factor &gt;= 1), &#34;invalid datatype for argument augm_fact or not greater than 1&#34;

    # append the connectivity matrix cols to X_img_cols and the rest to X_struc_cols
    X_img_cols = []
    X_struc_cols = []
    for x in X.columns:
        if len(x.split(&#34;_&#34;)) &gt; 1 and x.split(&#34;_&#34;)[0].isdigit() and x.split(&#34;_&#34;)[1].isdigit():
            X_img_cols.append(x)
        else:
            X_struc_cols.append(x)

    # apply data augmentation
    if augmentation:
        print(&#34;Starting Data Augmentation&#34;)
        X_img_aug, X_struc_aug, y_aug = augmented_data(X, y, X_img_cols, X_struc_cols, sd=scale,
                                                       augm_fact=augmentation_factor)
        # merging augmented data with input data
        X_img = pd.concat([X[X_img_cols], X_img_aug])
        X_struc = pd.concat([X[X_struc_cols], X_struc_aug])
        y = np.concatenate([np.array(y), y_aug], axis=0)
    else:
        X_img = X[X_img_cols]
        X_struc = X[X_struc_cols]
        y = np.array(y)

    print(&#34;Turning flat array to matrix&#34;)
    # turn flat array to matrix
    if aggregation:
        n_c = 8
        n_train = len(X_img)
        X_train_2d = np.zeros(n_train * n_c * n_c).reshape(n_train, n_c, n_c)

        # turn array to matrix
        for i in range(n_train):
            X_train_2d[i] = flat_to_mat_aggregation(X_img.iloc[i, :])

        stacked = np.stack(X_train_2d, axis=0)

    else:
        n_c = dtl.flat_to_mat(X_img.iloc[0, :]).shape[0]
        n_train = len(X_img)
        X_train_2d = np.zeros(n_train * n_c * n_c).reshape(n_train, n_c, n_c)

        # turn array to matrix
        for i in range(n_train):
            X_train_2d[i] = dtl.flat_to_mat(X_img.iloc[i, :])

        if reorder:
            stacked = np.stack(reorder_matrices_regions(X_train_2d, network=&#39;yeo7&#39;), axis=0)
        else:
            stacked = np.stack(X_train_2d, axis=0)

    # reshape data for the convolutional neural network
    X_img = stacked.reshape(stacked.shape[0], stacked.shape[1], stacked.shape[2], 1)
    if X_struc.shape[1] != 0:
        X_struc = X_struc.to_numpy().reshape(stacked.shape[0], 3)
    else:
        X_struc = X_struc.to_numpy()

    return X_img, X_struc, y</code></pre>
</details>
</dd>
<dt id="src.models.brainnet_cnn.preprocess_test_data_for_cnn"><code class="name flex">
<span>def <span class="ident">preprocess_test_data_for_cnn</span></span>(<span>X_test, y_test, aggregation=False, reorder=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Preprares the test dataset for evaluation</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>test dataframe</dd>
<dt><strong><code>y</code></strong></dt>
<dd>labels</dd>
<dt><strong><code>aggregation</code></strong></dt>
<dd>List of colnames of the connectivity matrix columns</dd>
<dt><strong><code>reorder</code></strong></dt>
<dd>List of colnames of the structural columns</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Test dataframe and labels. The test dataframe is returned as list if structrual information exists.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_test_data_for_cnn(X_test, y_test, aggregation=False, reorder=False):
    &#34;&#34;&#34;
    Preprares the test dataset for evaluation

    Args:
        x: test dataframe
        y: labels
        aggregation: List of colnames of the connectivity matrix columns
        reorder: List of colnames of the structural columns

    Returns:
        Test dataframe and labels. The test dataframe is returned as list if structrual information exists.
    &#34;&#34;&#34;
    assert isinstance(aggregation, bool), &#34;invalid datatype for argument aggregation&#34;
    assert isinstance(reorder, bool), &#34;invalid datatype for argument reorder&#34;

    X_test_img, X_test_struc, y_test = preprocess_for_cnn(X_test, y_test, aggregation=aggregation, reorder=reorder,
                                                          augmentation=False)

    # we have only connectivity matrices as input
    if X_test_struc.shape[1] == 0:
        return X_test_img, y_test
    # we have connectivity matrices as + structural information input
    else:
        return [X_test_img, X_test_struc], y_test</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.models" href="index.html">src.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.models.brainnet_cnn.augmented_data" href="#src.models.brainnet_cnn.augmented_data">augmented_data</a></code></li>
<li><code><a title="src.models.brainnet_cnn.brain_net_cnn" href="#src.models.brainnet_cnn.brain_net_cnn">brain_net_cnn</a></code></li>
<li><code><a title="src.models.brainnet_cnn.model_brainnet_cnn" href="#src.models.brainnet_cnn.model_brainnet_cnn">model_brainnet_cnn</a></code></li>
<li><code><a title="src.models.brainnet_cnn.preprocess_for_cnn" href="#src.models.brainnet_cnn.preprocess_for_cnn">preprocess_for_cnn</a></code></li>
<li><code><a title="src.models.brainnet_cnn.preprocess_test_data_for_cnn" href="#src.models.brainnet_cnn.preprocess_test_data_for_cnn">preprocess_test_data_for_cnn</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>