<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>src.preprocessing.preprocessing_matlab_files API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.preprocessing.preprocessing_matlab_files</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import numpy as np
import pandas as pd
import h5py
from sklearn.model_selection import train_test_split
from src.preprocessing.network_aggregation import grouped_conn_mat
from src.preprocessing.graph_metrics import is_conn_col, pd_to_arrays
from typing import Union


def preprocess_mat_files(matlab_dir: str = None,
                         excel_path: str = None,
                         export_file: bool = False,
                         write_dir: str = None,
                         preprocessing_type: str = &#39;conn&#39;,
                         network: str = &#39;yeo7&#39;,
                         upper: bool = True,
                         statistic: str = &#39;mean&#39;,
                         file_format: str = &#34;csv&#34;) -&gt; pd.DataFrame:

    &#34;&#34;&#34;
    Final function which combines all the other functions to read in
    and transform the data.

    Args:
        matlab_dir: path to matlab files
        excel_path: path to excel list
        export_file: If false return as pd dataframe
        write_dir: path where to write the dataset to if save_file = True
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix
        network: yeo7 or yeo17 network (only applicable if preprocessing_type = aggregation)
        statistic: Summary statistic to be applied
            - only applicable if preprocessing_type = aggregation
            - one of (mean, max, min and greater_zero)
        upper: boolean whether only upper diagonal elements of connecivity matrices should be used
        file_format: str. Pass &#34;h5&#34; for further modelling in python or &#34;csv&#34; for R (default &#34;csv&#34;)

    Returns:
        - DataFrame containing the processes matlab files + excel file
        - optionally saves a file (a train/test split of datasets) for further use in modelling.
    &#34;&#34;&#34;
    if matlab_dir is None:
        matlab_dir = input(r&#39;Input your path where the matlab files are stored: &#39;)
    if excel_path is None:
        excel_path = input(r&#39;Input your path where the excel &#39;
                           r&#39;file is stored (with name + &#34;.xlsx&#34;): &#39;)
    if write_dir is None:
        write_dir = input(r&#39;Input your path where &#39;
                          r&#39;to write the final file: &#39;)

    assert isinstance(matlab_dir, str), &#34;invalid path (matlab files) provided&#34;
    assert isinstance(excel_path, str), &#34;invalid path (excel file) provided&#34;
    assert isinstance(export_file, bool), &#34;invalid datatype for argument export_file&#34;
    assert isinstance(write_dir, str), &#34;invalid path (write_dir) provided&#34;
    assert isinstance(preprocessing_type, str) &amp; \
           (preprocessing_type == &#34;conn&#34; or
            preprocessing_type == &#34;aggregation&#34;), &#34;invalid preprocessing type&#34;
    assert isinstance(upper, bool), &#34;invalid datatype for argument flatten&#34;
    assert isinstance(file_format, str) &amp; \
           (file_format == &#34;csv&#34; or file_format == &#34;h5&#34;), &#34;invalid file format selected&#34;

    print(&#39;loading files&#39;)
    # load matlab files and excel
    res = load_matlab_files(matlab_dir)
    
    if not os.path.exists(excel_path):
        raise FileNotFoundError(&#34;invalid directory (excel file)&#34;)
    delcode_excel = pd.read_excel(excel_path)

    print(&#34;Starting Preprocessing&#34;)
    if preprocessing_type == &#39;conn&#39;:
        # stack matrices
        stacked = stack_matrices(res[0], upper, preprocessing_type)
        # creating colnames and merging into one df
        colnames = col_names_final_df(delcode_excel,
                                      res[0][0].shape[0],
                                      preprocessing_type)
    elif preprocessing_type == &#39;aggregation&#39;:
        grpd_conn_mat = grouped_conn_mat(res[0], network=network, statistic=statistic)

        # stack matrices
        stacked = stack_matrices(grpd_conn_mat, upper, preprocessing_type)
        # creating colnames and merging into one df
        colnames = col_names_final_df(delcode_excel,
                                      grpd_conn_mat[0].shape[0],
                                      preprocessing_type)

    print(&#34;Creating Final Dataset&#34;)
    final_df = create_final_df(file_names=res[1],
                               final_columns=colnames,
                               stacked_matrices=stacked,
                               data_from_excel=delcode_excel)
    if export_file:
        write_to_dir(dataset=final_df,
                     t_direct=write_dir,
                     file_format=file_format)
    print(&#34;Done!&#34;)
    return final_df


def load_matlab_files(directory: str) -&gt; tuple:
    &#34;&#34;&#34;
    imports all matlab files from specified directory

    Args:
        directory: Path to Matlab Files

    Returns:
        A list where the first argument is the collection of connectivity matrix
        and the 2nd argument is the names of the connectivity matrix

    Raises:
        KeyError: FileNotFoundError
    &#34;&#34;&#34;

    if not os.path.exists(directory):
        raise FileNotFoundError(&#34;invalid directory (matlab files)&#34;)

    mat_files_names = os.listdir(directory)
    mat_files_names = [os.path.join(directory, file) for file in mat_files_names]
    conn_matrices = []
    worked = []

    for i in mat_files_names:
        with h5py.File(i, &#39;r&#39;) as f:
            conn_matrices.append(np.array(f.get(&#34;Z&#34;)))
            worked.append(i)

    return conn_matrices, worked


def stack_matrices(matrices: list,
                   upper: bool = True,
                   preprocessing_type: str = &#39;conn&#39;) -&gt; np.ndarray:
    &#34;&#34;&#34;
    this function stacks the connectivity matrices
    for the subjects upon each other 
    so they can be used in a dataframe

    Args:
        matrices: List of connectivity matrix
        upper: whether only upper diagonal values should be considered
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        A flattenened np.ndarray of connectivtity matrices
    &#34;&#34;&#34;
    flattened = []
    for i in matrices:
        # error handling in case one matrix should not work?
        flattened.append(flatten_conn_matrix(i, upper, preprocessing_type))
        # error handling for stacking

    return np.stack(flattened, axis=0)


def flatten_conn_matrix(matrix: np.ndarray,
                        upper: bool = True,
                        preprocessing_type: str = &#39;conn&#39;) -&gt; np.ndarray:
    &#34;&#34;&#34;
    turns the connectivity matrix into a 1d array

    Args:
        matrix: A connectivity matrix
        upper: whether only the entries above the diagonal should be considered
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        flattened connectivity matrix as a 1d array
    &#34;&#34;&#34;
    assert isinstance(matrix, (np.ndarray, np.generic)), &#34;provided matrix is not an ndarray&#34;
    assert isinstance(upper, bool), &#34;invalid option selected - privided input to upper is no bool&#34;

    if upper:
        if preprocessing_type == &#39;conn&#39;:
            sh = matrix.shape[0]
            return matrix[np.triu_indices(sh, k=1)]
        elif preprocessing_type == &#39;aggregation&#39;:
            sh = matrix.shape[0]
            return matrix[np.triu_indices(sh, k=0)]

    else:
        return matrix.flatten()


def col_names_final_df(data_from_excel: pd.DataFrame,
                       shape: int = 246,
                       preprocessing_type: str = &#39;conn&#39;) -&gt; list:
    &#34;&#34;&#34;
    creates the columns names for the final data frame 
    based on shape / number of columns of the used connectivity matrix


    Args:
        data_from_excel: A pd.Dataframe
        shape: number of columns in connectivity matrix
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        A list of column names for the final dataset
    &#34;&#34;&#34;
    assert isinstance(data_from_excel, pd.DataFrame), &#34;provided data_from_excel is no pd.DataFrame&#34;

    colnames = [&#34;IDs&#34;]
    colnames = colnames + col_names_conn_matrix(shape, preprocessing_type)
    final_columns = list(data_from_excel.columns) + colnames
    return final_columns


def col_names_conn_matrix(n: int,
                          preprocessing_type: str = &#39;conn&#39;):
    &#34;&#34;&#34;
    creates the column names for the flattened connectivity matrix


    Args:
        n: number of columns in connectivity matrix
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        Column names for connectivity matrix
    &#34;&#34;&#34;
    if preprocessing_type == &#39;conn&#39;:
        return [str(i) + &#34;_&#34; + str(j) for i in range(1, n + 1)
                for j in range(i + 1, n + 1)]
    elif preprocessing_type == &#39;aggregation&#39;:
        return [str(i) + &#34;_&#34; + str(j) for i in range(0, n) for j in range(i, n)]


def create_final_df(file_names: list,
                    final_columns: list,
                    stacked_matrices: np.ndarray,
                    data_from_excel: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    this function merges the connectivity matrices, the excel and the subject ids

    Args:
        file_names:  list of matlab file names
        final_columns:  list of final column names
        stacked_matrices:  a stacked connectivity matrix
        data_from_excel:  a pd Dataframe with extra information on patients


    Returns:
        A Merged dataframe of connectivity matrix + patient information
    &#34;&#34;&#34;
    assert isinstance(file_names, list), &#34;no list of file names provided&#34;
    assert isinstance(final_columns, list), &#34;no list of final column names provided&#34;
    assert isinstance(stacked_matrices, np.ndarray), &#34;provided connectivity matrices are no array&#34;
    assert isinstance(data_from_excel, pd.DataFrame), &#34;provided data_from_excel is no pd.DataFrame&#34;

    ids = get_subject_ids(file_names)
    ids_added = np.c_[ids, stacked_matrices]
    ids_added_df = pd.DataFrame(ids_added) # create df, first column contains IDs

    # final_columns = col_names_final_df(data_from_excel = data_from_excel)
    final_df_0 = data_from_excel.merge(ids_added_df, left_on = &#39;ConnID&#39;, right_on = 0) # merge two data frames by connID column/first column of ids_added_df
    final_df = pd.DataFrame(np.array(final_df_0), columns=final_columns) # rename columns

    return final_df


def get_subject_ids(file_names: list) -&gt; np.ndarray:
    &#34;&#34;&#34;
    gets the subjectIDs if the filenames correspond to the 
    used format: resultsROI_Subject006_Condition001.mat
    would correspond to subject ID 6

    Args:
        file_names:  list of matlab file names

    Returns:
        A np.ndarray in a readable format
    &#34;&#34;&#34;
    assert isinstance(file_names, list), &#34;no list of file names provided&#34;

    return np.array([int(i.split(&#34;Subject&#34;, 1)[1][0:3]) for i in file_names])


def create_train_test_split(data: pd.DataFrame,
                            split_size: float = .8,
                            seed: int = 42) -&gt; list:
    &#34;&#34;&#34;
    takes the final data set and splits it into random train and test subsets. 
    Returns a list containing train-test split of inputs
    
    Args:
        data: dataset to be split into train/test
        split_size: the size of the train dataset (default .8)
        seed: pass an int for reproducibility purposes

    Returns:
        A list containing train-test split of inputs
    &#34;&#34;&#34;
    # assert split size between 0 and 1
    assert 0 &lt;= split_size &lt;= 1, &#34;split_size out of bounds&#34;
    assert isinstance(data, pd.DataFrame), &#34;no DataFrame provided&#34;
    assert isinstance(seed, int), &#34;provided seed is no integer&#34;

    # split into features and target
    #     features = data.drop(&#39;target&#39;, axis=1)
    #     target = data[&#39;target&#39;]

    # stratify by the target to ensure equal distribution
    return train_test_split(data, train_size=split_size, random_state=seed, shuffle=True)


def write_to_dir(dataset: pd.DataFrame,
                 t_direct: str = None,
                 file_format: str = &#34;csv&#34;) -&gt; None:
    &#34;&#34;&#34;
    writes the list of train/test splits to hdf files for future use in python or
    csv for future use in R into the specified directory

    Args:
        dataset: the final dataset to save
        t_direct: path where to save the dataframes to
        file_format: The fileformat the data should be saved as (csv of hdf)
            -&gt; input must be csv or h5

    Returns:
        None - saves a csv or hdf file

    Raises:
        FileNotFoundError
    &#34;&#34;&#34;
    assert isinstance(t_direct, str), &#34;invalid path (write_dir) provided&#34;
    assert isinstance(dataset, pd.DataFrame), &#34;no DataFrame provided&#34;
    assert isinstance(file_format, str) &amp; \
           ((file_format == &#34;csv&#34;) | (file_format == &#34;h5&#34;)), \
        &#34;invalid file format selected&#34;

    if not os.path.exists(t_direct):
        raise FileNotFoundError(&#34;invalid path (write to dir)&#34;)

    filename = os.path.join(t_direct, (&#34;preprocessed_df.h5&#34;
                                       if file_format == &#34;h5&#34;
                                       else &#34;preprocessed_df.csv&#34;))

    if file_format == &#34;h5&#34;:
        dataset.to_hdf(filename, key=&#39;df&#39;, mode=&#39;w&#39;)
    elif file_format == &#34;csv&#34;:
        dataset.to_csv(filename, index=False)


def grouped_conn_df(data: pd.DataFrame,
                    regions: list = None,
                    cols: list = None,
                    return_arrays: bool = True,
                    stack_options: dict = None,
                    **kwargs) -&gt; Union[list, pd.DataFrame]:
    &#34;&#34;&#34;
    function to compute the grouped / aggregated conn matrices from a pd.DataFrame
    Args:
        data: dataFrame containing the conn data
        regions: list of names of the regions of the conn matrix in case reordered
                 IMPORTANT: region names AFTER aggregation needed
        cols: list of columns of the DataFrame data which contain conn data
        return_arrays: whether the aggregated data should be returned in the form
            of arrays or a dataframe
        stack_options: options passed to &#34;stack_matrices&#34;
        **kwargs: anything that´s passed to &#34;grouped_conn_mat&#34;
    Returns:
        list containing the grouped connectivity matrices or dataFrame
    &#34;&#34;&#34;
    if stack_options is None:
        stack_options = {&#34;upper&#34;: True,
                         &#34;preprocessing_type&#34;: &#39;conn&#39;}

    arrays = pd_to_arrays(data, cols)
    grouped_conn = grouped_conn_mat(conn_matrices=arrays,
                                   **kwargs)
    if return_arrays:
        return grouped_conn

    stacked = stack_matrices(grouped_conn, **stack_options)
    p = grouped_conn[0].shape[0]

    if regions is None:
        regions = [str(i+1) + &#34;_&#34; + str(j+1)
                   for i in range(p)
                   for j in range(i+1, p)]

    return pd.DataFrame(stacked, columns=regions)


def main():
    preprocessing_type = input(r&#39;Input preprocessing type: conn, aggregation or grouped: &#39;)
    if preprocessing_type == &#34;aggregation&#34;:
        statistic = input(r&#39;Input summary statistic: &#39;)
        preprocess_mat_files(preprocessing_type=preprocessing_type, statistic=statistic)
    else:
        preprocess_mat_files(preprocessing_type=preprocessing_type)


def test_grouped_conn_df():
    # NOTE: use the following to build unittests later
    # checking the get_gms_from_pd function
    k = 246  # dim of the conn matrix
    obs = 10  # observations
    conn = pd.DataFrame(
        np.random.normal(
            loc=0.1,
            scale=1.2,
            size=int((k*(k-1)/2)*obs)).reshape(obs, int((k*(k-1)/2))),
            columns=[str(i) + &#34;_&#34; + str(j)
                     for i in range(k)
                     for j in range(i+1, k)])
    print(&#34;data&#34;)
    print(conn)
    # check option returning arrays
    res = grouped_conn_df(conn)
    print(&#34;result&#34;)
    print(res)

    print(len(res))
    print(&#34;checking for correctness of shape&#34;)
    print([r.shape for r in res])

    # check option returning DataFrame
    res = grouped_conn_df(conn, return_arrays=False)
    print(&#34;result DF&#34;)
    print(res)

    print(len(res))
    print(&#34;checking for correctness of shape&#34;)
    print(res.shape)


if __name__ == &#34;__main__&#34;:
    test_grouped_conn_df()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.preprocessing.preprocessing_matlab_files.col_names_conn_matrix"><code class="name flex">
<span>def <span class="ident">col_names_conn_matrix</span></span>(<span>n: int, preprocessing_type: str = 'conn')</span>
</code></dt>
<dd>
<div class="desc"><p>creates the column names for the flattened connectivity matrix</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong></dt>
<dd>number of columns in connectivity matrix</dd>
<dt><strong><code>preprocessing_type</code></strong></dt>
<dd>conn for connectivity matrix,
"aggregation" for aggregated conn matrix, "graph" for graph matrices</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Column names for connectivity matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def col_names_conn_matrix(n: int,
                          preprocessing_type: str = &#39;conn&#39;):
    &#34;&#34;&#34;
    creates the column names for the flattened connectivity matrix


    Args:
        n: number of columns in connectivity matrix
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        Column names for connectivity matrix
    &#34;&#34;&#34;
    if preprocessing_type == &#39;conn&#39;:
        return [str(i) + &#34;_&#34; + str(j) for i in range(1, n + 1)
                for j in range(i + 1, n + 1)]
    elif preprocessing_type == &#39;aggregation&#39;:
        return [str(i) + &#34;_&#34; + str(j) for i in range(0, n) for j in range(i, n)]</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.col_names_final_df"><code class="name flex">
<span>def <span class="ident">col_names_final_df</span></span>(<span>data_from_excel: pandas.core.frame.DataFrame, shape: int = 246, preprocessing_type: str = 'conn') ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>creates the columns names for the final data frame
based on shape / number of columns of the used connectivity matrix</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data_from_excel</code></strong></dt>
<dd>A pd.Dataframe</dd>
<dt><strong><code>shape</code></strong></dt>
<dd>number of columns in connectivity matrix</dd>
<dt><strong><code>preprocessing_type</code></strong></dt>
<dd>conn for connectivity matrix,
"aggregation" for aggregated conn matrix, "graph" for graph matrices</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of column names for the final dataset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def col_names_final_df(data_from_excel: pd.DataFrame,
                       shape: int = 246,
                       preprocessing_type: str = &#39;conn&#39;) -&gt; list:
    &#34;&#34;&#34;
    creates the columns names for the final data frame 
    based on shape / number of columns of the used connectivity matrix


    Args:
        data_from_excel: A pd.Dataframe
        shape: number of columns in connectivity matrix
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        A list of column names for the final dataset
    &#34;&#34;&#34;
    assert isinstance(data_from_excel, pd.DataFrame), &#34;provided data_from_excel is no pd.DataFrame&#34;

    colnames = [&#34;IDs&#34;]
    colnames = colnames + col_names_conn_matrix(shape, preprocessing_type)
    final_columns = list(data_from_excel.columns) + colnames
    return final_columns</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.create_final_df"><code class="name flex">
<span>def <span class="ident">create_final_df</span></span>(<span>file_names: list, final_columns: list, stacked_matrices: numpy.ndarray, data_from_excel: pandas.core.frame.DataFrame) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>this function merges the connectivity matrices, the excel and the subject ids</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_names</code></strong></dt>
<dd>list of matlab file names</dd>
<dt><strong><code>final_columns</code></strong></dt>
<dd>list of final column names</dd>
<dt><strong><code>stacked_matrices</code></strong></dt>
<dd>a stacked connectivity matrix</dd>
<dt><strong><code>data_from_excel</code></strong></dt>
<dd>a pd Dataframe with extra information on patients</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A Merged dataframe of connectivity matrix + patient information</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_final_df(file_names: list,
                    final_columns: list,
                    stacked_matrices: np.ndarray,
                    data_from_excel: pd.DataFrame) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    this function merges the connectivity matrices, the excel and the subject ids

    Args:
        file_names:  list of matlab file names
        final_columns:  list of final column names
        stacked_matrices:  a stacked connectivity matrix
        data_from_excel:  a pd Dataframe with extra information on patients


    Returns:
        A Merged dataframe of connectivity matrix + patient information
    &#34;&#34;&#34;
    assert isinstance(file_names, list), &#34;no list of file names provided&#34;
    assert isinstance(final_columns, list), &#34;no list of final column names provided&#34;
    assert isinstance(stacked_matrices, np.ndarray), &#34;provided connectivity matrices are no array&#34;
    assert isinstance(data_from_excel, pd.DataFrame), &#34;provided data_from_excel is no pd.DataFrame&#34;

    ids = get_subject_ids(file_names)
    ids_added = np.c_[ids, stacked_matrices]
    ids_added_df = pd.DataFrame(ids_added) # create df, first column contains IDs

    # final_columns = col_names_final_df(data_from_excel = data_from_excel)
    final_df_0 = data_from_excel.merge(ids_added_df, left_on = &#39;ConnID&#39;, right_on = 0) # merge two data frames by connID column/first column of ids_added_df
    final_df = pd.DataFrame(np.array(final_df_0), columns=final_columns) # rename columns

    return final_df</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.create_train_test_split"><code class="name flex">
<span>def <span class="ident">create_train_test_split</span></span>(<span>data: pandas.core.frame.DataFrame, split_size: float = 0.8, seed: int = 42) ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>takes the final data set and splits it into random train and test subsets.
Returns a list containing train-test split of inputs</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong></dt>
<dd>dataset to be split into train/test</dd>
<dt><strong><code>split_size</code></strong></dt>
<dd>the size of the train dataset (default .8)</dd>
<dt><strong><code>seed</code></strong></dt>
<dd>pass an int for reproducibility purposes</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list containing train-test split of inputs</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_train_test_split(data: pd.DataFrame,
                            split_size: float = .8,
                            seed: int = 42) -&gt; list:
    &#34;&#34;&#34;
    takes the final data set and splits it into random train and test subsets. 
    Returns a list containing train-test split of inputs
    
    Args:
        data: dataset to be split into train/test
        split_size: the size of the train dataset (default .8)
        seed: pass an int for reproducibility purposes

    Returns:
        A list containing train-test split of inputs
    &#34;&#34;&#34;
    # assert split size between 0 and 1
    assert 0 &lt;= split_size &lt;= 1, &#34;split_size out of bounds&#34;
    assert isinstance(data, pd.DataFrame), &#34;no DataFrame provided&#34;
    assert isinstance(seed, int), &#34;provided seed is no integer&#34;

    # split into features and target
    #     features = data.drop(&#39;target&#39;, axis=1)
    #     target = data[&#39;target&#39;]

    # stratify by the target to ensure equal distribution
    return train_test_split(data, train_size=split_size, random_state=seed, shuffle=True)</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.flatten_conn_matrix"><code class="name flex">
<span>def <span class="ident">flatten_conn_matrix</span></span>(<span>matrix: numpy.ndarray, upper: bool = True, preprocessing_type: str = 'conn') ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>turns the connectivity matrix into a 1d array</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>matrix</code></strong></dt>
<dd>A connectivity matrix</dd>
<dt><strong><code>upper</code></strong></dt>
<dd>whether only the entries above the diagonal should be considered</dd>
<dt><strong><code>preprocessing_type</code></strong></dt>
<dd>conn for connectivity matrix,
"aggregation" for aggregated conn matrix, "graph" for graph matrices</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>flattened connectivity matrix as a 1d array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flatten_conn_matrix(matrix: np.ndarray,
                        upper: bool = True,
                        preprocessing_type: str = &#39;conn&#39;) -&gt; np.ndarray:
    &#34;&#34;&#34;
    turns the connectivity matrix into a 1d array

    Args:
        matrix: A connectivity matrix
        upper: whether only the entries above the diagonal should be considered
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        flattened connectivity matrix as a 1d array
    &#34;&#34;&#34;
    assert isinstance(matrix, (np.ndarray, np.generic)), &#34;provided matrix is not an ndarray&#34;
    assert isinstance(upper, bool), &#34;invalid option selected - privided input to upper is no bool&#34;

    if upper:
        if preprocessing_type == &#39;conn&#39;:
            sh = matrix.shape[0]
            return matrix[np.triu_indices(sh, k=1)]
        elif preprocessing_type == &#39;aggregation&#39;:
            sh = matrix.shape[0]
            return matrix[np.triu_indices(sh, k=0)]

    else:
        return matrix.flatten()</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.get_subject_ids"><code class="name flex">
<span>def <span class="ident">get_subject_ids</span></span>(<span>file_names: list) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>gets the subjectIDs if the filenames correspond to the
used format: resultsROI_Subject006_Condition001.mat
would correspond to subject ID 6</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_names</code></strong></dt>
<dd>list of matlab file names</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A np.ndarray in a readable format</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_subject_ids(file_names: list) -&gt; np.ndarray:
    &#34;&#34;&#34;
    gets the subjectIDs if the filenames correspond to the 
    used format: resultsROI_Subject006_Condition001.mat
    would correspond to subject ID 6

    Args:
        file_names:  list of matlab file names

    Returns:
        A np.ndarray in a readable format
    &#34;&#34;&#34;
    assert isinstance(file_names, list), &#34;no list of file names provided&#34;

    return np.array([int(i.split(&#34;Subject&#34;, 1)[1][0:3]) for i in file_names])</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.grouped_conn_df"><code class="name flex">
<span>def <span class="ident">grouped_conn_df</span></span>(<span>data: pandas.core.frame.DataFrame, regions: list = None, cols: list = None, return_arrays: bool = True, stack_options: dict = None, **kwargs) ‑> Union[list, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>function to compute the grouped / aggregated conn matrices from a pd.DataFrame</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong></dt>
<dd>dataFrame containing the conn data</dd>
<dt><strong><code>regions</code></strong></dt>
<dd>list of names of the regions of the conn matrix in case reordered
IMPORTANT: region names AFTER aggregation needed</dd>
<dt><strong><code>cols</code></strong></dt>
<dd>list of columns of the DataFrame data which contain conn data</dd>
<dt><strong><code>return_arrays</code></strong></dt>
<dd>whether the aggregated data should be returned in the form
of arrays or a dataframe</dd>
<dt><strong><code>stack_options</code></strong></dt>
<dd>options passed to "stack_matrices"</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>anything that´s passed to "grouped_conn_mat"</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>list containing the grouped connectivity matrices or dataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def grouped_conn_df(data: pd.DataFrame,
                    regions: list = None,
                    cols: list = None,
                    return_arrays: bool = True,
                    stack_options: dict = None,
                    **kwargs) -&gt; Union[list, pd.DataFrame]:
    &#34;&#34;&#34;
    function to compute the grouped / aggregated conn matrices from a pd.DataFrame
    Args:
        data: dataFrame containing the conn data
        regions: list of names of the regions of the conn matrix in case reordered
                 IMPORTANT: region names AFTER aggregation needed
        cols: list of columns of the DataFrame data which contain conn data
        return_arrays: whether the aggregated data should be returned in the form
            of arrays or a dataframe
        stack_options: options passed to &#34;stack_matrices&#34;
        **kwargs: anything that´s passed to &#34;grouped_conn_mat&#34;
    Returns:
        list containing the grouped connectivity matrices or dataFrame
    &#34;&#34;&#34;
    if stack_options is None:
        stack_options = {&#34;upper&#34;: True,
                         &#34;preprocessing_type&#34;: &#39;conn&#39;}

    arrays = pd_to_arrays(data, cols)
    grouped_conn = grouped_conn_mat(conn_matrices=arrays,
                                   **kwargs)
    if return_arrays:
        return grouped_conn

    stacked = stack_matrices(grouped_conn, **stack_options)
    p = grouped_conn[0].shape[0]

    if regions is None:
        regions = [str(i+1) + &#34;_&#34; + str(j+1)
                   for i in range(p)
                   for j in range(i+1, p)]

    return pd.DataFrame(stacked, columns=regions)</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.load_matlab_files"><code class="name flex">
<span>def <span class="ident">load_matlab_files</span></span>(<span>directory: str) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>imports all matlab files from specified directory</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>directory</code></strong></dt>
<dd>Path to Matlab Files</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list where the first argument is the collection of connectivity matrix
and the 2nd argument is the names of the connectivity matrix</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>KeyError</code></dt>
<dd>FileNotFoundError</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_matlab_files(directory: str) -&gt; tuple:
    &#34;&#34;&#34;
    imports all matlab files from specified directory

    Args:
        directory: Path to Matlab Files

    Returns:
        A list where the first argument is the collection of connectivity matrix
        and the 2nd argument is the names of the connectivity matrix

    Raises:
        KeyError: FileNotFoundError
    &#34;&#34;&#34;

    if not os.path.exists(directory):
        raise FileNotFoundError(&#34;invalid directory (matlab files)&#34;)

    mat_files_names = os.listdir(directory)
    mat_files_names = [os.path.join(directory, file) for file in mat_files_names]
    conn_matrices = []
    worked = []

    for i in mat_files_names:
        with h5py.File(i, &#39;r&#39;) as f:
            conn_matrices.append(np.array(f.get(&#34;Z&#34;)))
            worked.append(i)

    return conn_matrices, worked</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main():
    preprocessing_type = input(r&#39;Input preprocessing type: conn, aggregation or grouped: &#39;)
    if preprocessing_type == &#34;aggregation&#34;:
        statistic = input(r&#39;Input summary statistic: &#39;)
        preprocess_mat_files(preprocessing_type=preprocessing_type, statistic=statistic)
    else:
        preprocess_mat_files(preprocessing_type=preprocessing_type)</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.preprocess_mat_files"><code class="name flex">
<span>def <span class="ident">preprocess_mat_files</span></span>(<span>matlab_dir: str = None, excel_path: str = None, export_file: bool = False, write_dir: str = None, preprocessing_type: str = 'conn', network: str = 'yeo7', upper: bool = True, statistic: str = 'mean', file_format: str = 'csv') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Final function which combines all the other functions to read in
and transform the data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>matlab_dir</code></strong></dt>
<dd>path to matlab files</dd>
<dt><strong><code>excel_path</code></strong></dt>
<dd>path to excel list</dd>
<dt><strong><code>export_file</code></strong></dt>
<dd>If false return as pd dataframe</dd>
<dt><strong><code>write_dir</code></strong></dt>
<dd>path where to write the dataset to if save_file = True</dd>
<dt><strong><code>preprocessing_type</code></strong></dt>
<dd>conn for connectivity matrix,
"aggregation" for aggregated conn matrix</dd>
<dt><strong><code>network</code></strong></dt>
<dd>yeo7 or yeo17 network (only applicable if preprocessing_type = aggregation)</dd>
<dt><strong><code>statistic</code></strong></dt>
<dd>Summary statistic to be applied
- only applicable if preprocessing_type = aggregation
- one of (mean, max, min and greater_zero)</dd>
<dt><strong><code>upper</code></strong></dt>
<dd>boolean whether only upper diagonal elements of connecivity matrices should be used</dd>
<dt><strong><code>file_format</code></strong></dt>
<dd>str. Pass "h5" for further modelling in python or "csv" for R (default "csv")</dd>
</dl>
<h2 id="returns">Returns</h2>
<ul>
<li>DataFrame containing the processes matlab files + excel file</li>
<li>optionally saves a file (a train/test split of datasets) for further use in modelling.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_mat_files(matlab_dir: str = None,
                         excel_path: str = None,
                         export_file: bool = False,
                         write_dir: str = None,
                         preprocessing_type: str = &#39;conn&#39;,
                         network: str = &#39;yeo7&#39;,
                         upper: bool = True,
                         statistic: str = &#39;mean&#39;,
                         file_format: str = &#34;csv&#34;) -&gt; pd.DataFrame:

    &#34;&#34;&#34;
    Final function which combines all the other functions to read in
    and transform the data.

    Args:
        matlab_dir: path to matlab files
        excel_path: path to excel list
        export_file: If false return as pd dataframe
        write_dir: path where to write the dataset to if save_file = True
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix
        network: yeo7 or yeo17 network (only applicable if preprocessing_type = aggregation)
        statistic: Summary statistic to be applied
            - only applicable if preprocessing_type = aggregation
            - one of (mean, max, min and greater_zero)
        upper: boolean whether only upper diagonal elements of connecivity matrices should be used
        file_format: str. Pass &#34;h5&#34; for further modelling in python or &#34;csv&#34; for R (default &#34;csv&#34;)

    Returns:
        - DataFrame containing the processes matlab files + excel file
        - optionally saves a file (a train/test split of datasets) for further use in modelling.
    &#34;&#34;&#34;
    if matlab_dir is None:
        matlab_dir = input(r&#39;Input your path where the matlab files are stored: &#39;)
    if excel_path is None:
        excel_path = input(r&#39;Input your path where the excel &#39;
                           r&#39;file is stored (with name + &#34;.xlsx&#34;): &#39;)
    if write_dir is None:
        write_dir = input(r&#39;Input your path where &#39;
                          r&#39;to write the final file: &#39;)

    assert isinstance(matlab_dir, str), &#34;invalid path (matlab files) provided&#34;
    assert isinstance(excel_path, str), &#34;invalid path (excel file) provided&#34;
    assert isinstance(export_file, bool), &#34;invalid datatype for argument export_file&#34;
    assert isinstance(write_dir, str), &#34;invalid path (write_dir) provided&#34;
    assert isinstance(preprocessing_type, str) &amp; \
           (preprocessing_type == &#34;conn&#34; or
            preprocessing_type == &#34;aggregation&#34;), &#34;invalid preprocessing type&#34;
    assert isinstance(upper, bool), &#34;invalid datatype for argument flatten&#34;
    assert isinstance(file_format, str) &amp; \
           (file_format == &#34;csv&#34; or file_format == &#34;h5&#34;), &#34;invalid file format selected&#34;

    print(&#39;loading files&#39;)
    # load matlab files and excel
    res = load_matlab_files(matlab_dir)
    
    if not os.path.exists(excel_path):
        raise FileNotFoundError(&#34;invalid directory (excel file)&#34;)
    delcode_excel = pd.read_excel(excel_path)

    print(&#34;Starting Preprocessing&#34;)
    if preprocessing_type == &#39;conn&#39;:
        # stack matrices
        stacked = stack_matrices(res[0], upper, preprocessing_type)
        # creating colnames and merging into one df
        colnames = col_names_final_df(delcode_excel,
                                      res[0][0].shape[0],
                                      preprocessing_type)
    elif preprocessing_type == &#39;aggregation&#39;:
        grpd_conn_mat = grouped_conn_mat(res[0], network=network, statistic=statistic)

        # stack matrices
        stacked = stack_matrices(grpd_conn_mat, upper, preprocessing_type)
        # creating colnames and merging into one df
        colnames = col_names_final_df(delcode_excel,
                                      grpd_conn_mat[0].shape[0],
                                      preprocessing_type)

    print(&#34;Creating Final Dataset&#34;)
    final_df = create_final_df(file_names=res[1],
                               final_columns=colnames,
                               stacked_matrices=stacked,
                               data_from_excel=delcode_excel)
    if export_file:
        write_to_dir(dataset=final_df,
                     t_direct=write_dir,
                     file_format=file_format)
    print(&#34;Done!&#34;)
    return final_df</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.stack_matrices"><code class="name flex">
<span>def <span class="ident">stack_matrices</span></span>(<span>matrices: list, upper: bool = True, preprocessing_type: str = 'conn') ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>this function stacks the connectivity matrices
for the subjects upon each other
so they can be used in a dataframe</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>matrices</code></strong></dt>
<dd>List of connectivity matrix</dd>
<dt><strong><code>upper</code></strong></dt>
<dd>whether only upper diagonal values should be considered</dd>
<dt><strong><code>preprocessing_type</code></strong></dt>
<dd>conn for connectivity matrix,
"aggregation" for aggregated conn matrix, "graph" for graph matrices</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A flattenened np.ndarray of connectivtity matrices</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stack_matrices(matrices: list,
                   upper: bool = True,
                   preprocessing_type: str = &#39;conn&#39;) -&gt; np.ndarray:
    &#34;&#34;&#34;
    this function stacks the connectivity matrices
    for the subjects upon each other 
    so they can be used in a dataframe

    Args:
        matrices: List of connectivity matrix
        upper: whether only upper diagonal values should be considered
        preprocessing_type: conn for connectivity matrix,
            &#34;aggregation&#34; for aggregated conn matrix, &#34;graph&#34; for graph matrices

    Returns:
        A flattenened np.ndarray of connectivtity matrices
    &#34;&#34;&#34;
    flattened = []
    for i in matrices:
        # error handling in case one matrix should not work?
        flattened.append(flatten_conn_matrix(i, upper, preprocessing_type))
        # error handling for stacking

    return np.stack(flattened, axis=0)</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.test_grouped_conn_df"><code class="name flex">
<span>def <span class="ident">test_grouped_conn_df</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_grouped_conn_df():
    # NOTE: use the following to build unittests later
    # checking the get_gms_from_pd function
    k = 246  # dim of the conn matrix
    obs = 10  # observations
    conn = pd.DataFrame(
        np.random.normal(
            loc=0.1,
            scale=1.2,
            size=int((k*(k-1)/2)*obs)).reshape(obs, int((k*(k-1)/2))),
            columns=[str(i) + &#34;_&#34; + str(j)
                     for i in range(k)
                     for j in range(i+1, k)])
    print(&#34;data&#34;)
    print(conn)
    # check option returning arrays
    res = grouped_conn_df(conn)
    print(&#34;result&#34;)
    print(res)

    print(len(res))
    print(&#34;checking for correctness of shape&#34;)
    print([r.shape for r in res])

    # check option returning DataFrame
    res = grouped_conn_df(conn, return_arrays=False)
    print(&#34;result DF&#34;)
    print(res)

    print(len(res))
    print(&#34;checking for correctness of shape&#34;)
    print(res.shape)</code></pre>
</details>
</dd>
<dt id="src.preprocessing.preprocessing_matlab_files.write_to_dir"><code class="name flex">
<span>def <span class="ident">write_to_dir</span></span>(<span>dataset: pandas.core.frame.DataFrame, t_direct: str = None, file_format: str = 'csv') ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>writes the list of train/test splits to hdf files for future use in python or
csv for future use in R into the specified directory</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset</code></strong></dt>
<dd>the final dataset to save</dd>
<dt><strong><code>t_direct</code></strong></dt>
<dd>path where to save the dataframes to</dd>
<dt><strong><code>file_format</code></strong></dt>
<dd>The fileformat the data should be saved as (csv of hdf)
-&gt; input must be csv or h5</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None - saves a csv or hdf file</p>
<h2 id="raises">Raises</h2>
<p>FileNotFoundError</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_to_dir(dataset: pd.DataFrame,
                 t_direct: str = None,
                 file_format: str = &#34;csv&#34;) -&gt; None:
    &#34;&#34;&#34;
    writes the list of train/test splits to hdf files for future use in python or
    csv for future use in R into the specified directory

    Args:
        dataset: the final dataset to save
        t_direct: path where to save the dataframes to
        file_format: The fileformat the data should be saved as (csv of hdf)
            -&gt; input must be csv or h5

    Returns:
        None - saves a csv or hdf file

    Raises:
        FileNotFoundError
    &#34;&#34;&#34;
    assert isinstance(t_direct, str), &#34;invalid path (write_dir) provided&#34;
    assert isinstance(dataset, pd.DataFrame), &#34;no DataFrame provided&#34;
    assert isinstance(file_format, str) &amp; \
           ((file_format == &#34;csv&#34;) | (file_format == &#34;h5&#34;)), \
        &#34;invalid file format selected&#34;

    if not os.path.exists(t_direct):
        raise FileNotFoundError(&#34;invalid path (write to dir)&#34;)

    filename = os.path.join(t_direct, (&#34;preprocessed_df.h5&#34;
                                       if file_format == &#34;h5&#34;
                                       else &#34;preprocessed_df.csv&#34;))

    if file_format == &#34;h5&#34;:
        dataset.to_hdf(filename, key=&#39;df&#39;, mode=&#39;w&#39;)
    elif file_format == &#34;csv&#34;:
        dataset.to_csv(filename, index=False)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.preprocessing" href="index.html">src.preprocessing</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.preprocessing.preprocessing_matlab_files.col_names_conn_matrix" href="#src.preprocessing.preprocessing_matlab_files.col_names_conn_matrix">col_names_conn_matrix</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.col_names_final_df" href="#src.preprocessing.preprocessing_matlab_files.col_names_final_df">col_names_final_df</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.create_final_df" href="#src.preprocessing.preprocessing_matlab_files.create_final_df">create_final_df</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.create_train_test_split" href="#src.preprocessing.preprocessing_matlab_files.create_train_test_split">create_train_test_split</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.flatten_conn_matrix" href="#src.preprocessing.preprocessing_matlab_files.flatten_conn_matrix">flatten_conn_matrix</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.get_subject_ids" href="#src.preprocessing.preprocessing_matlab_files.get_subject_ids">get_subject_ids</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.grouped_conn_df" href="#src.preprocessing.preprocessing_matlab_files.grouped_conn_df">grouped_conn_df</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.load_matlab_files" href="#src.preprocessing.preprocessing_matlab_files.load_matlab_files">load_matlab_files</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.main" href="#src.preprocessing.preprocessing_matlab_files.main">main</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.preprocess_mat_files" href="#src.preprocessing.preprocessing_matlab_files.preprocess_mat_files">preprocess_mat_files</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.stack_matrices" href="#src.preprocessing.preprocessing_matlab_files.stack_matrices">stack_matrices</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.test_grouped_conn_df" href="#src.preprocessing.preprocessing_matlab_files.test_grouped_conn_df">test_grouped_conn_df</a></code></li>
<li><code><a title="src.preprocessing.preprocessing_matlab_files.write_to_dir" href="#src.preprocessing.preprocessing_matlab_files.write_to_dir">write_to_dir</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>